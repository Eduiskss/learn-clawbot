# Conversation Agent æŠ€æœ¯æ¶æ„æ–‡æ¡£

> ç‰ˆæœ¬: v3.9 | æ›´æ–°æ—¥æœŸ: 2026-01-26 | æ¡†æ¶: LangGraph 1.0
> 
> **ç›®æ ‡è¯»è€…**: AI ä¸“å®¶ï¼Œç”¨äºæŠ€æœ¯è®¨è®ºä¸ä¼˜åŒ–

---

## ä¸€ã€ç³»ç»Ÿæ¦‚è¿°

### 1.1 æ ¸å¿ƒå®šä½

**é¦–å…¬é‡Œæ™ºèƒ½æ’ç­åŠ©æ‰‹**æ˜¯ä¸€ä¸ªåŸºäº LangGraph 1.0 çš„**ç”Ÿäº§çº§å¯¹è¯ Agent ç³»ç»Ÿ**ï¼Œä¸“ä¸ºå›½é™…ç‰©æµä»“åº“è¿è¥åœºæ™¯è®¾è®¡ã€‚

**æ ¸å¿ƒèƒ½åŠ›**ï¼š
- åŒè·¯å¾„å¯¹è¯æµç¨‹ï¼ˆStandard + Complexï¼‰
- æ•°æ®æŸ¥è¯¢ä¸åˆ†æï¼ˆé¢„æµ‹/å®é™…/ç»¼åˆï¼‰
- çŸ¥è¯†å›¾è°±ç›‘æ§ï¼ˆ18ä¸ªKGå·¥å…·ï¼‰
- å°æ—¶çº§æµé€Ÿåˆ†æ
- ç”¨æˆ·è®°å¿†ç³»ç»Ÿï¼ˆä¸ªæ€§åŒ–æ¨ç†ï¼‰
- Human-in-the-Loop å®¡æ‰¹

### 1.2 æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|----------|------|
| Agent æ¡†æ¶ | LangGraph 1.0.3 | StateGraph + Checkpointer + Store |
| LLM | Qwen (é€šä¹‰åƒé—®) | qwen_analysisï¼ˆæ¨ç†ï¼‰+ qwen_fastï¼ˆåˆ†ç±»ï¼‰ |
| å‘é‡åµŒå…¥ | text-embedding-v4 | 1536ç»´ï¼Œå¼‚æ­¥è°ƒç”¨æ”¯æŒ |
| æŒä¹…åŒ– | PostgreSQL 14+ | AsyncPostgresSaver + AsyncPostgresStore |
| å›¾æ•°æ®åº“ | PolarDB AGE | Apache AGE å…¼å®¹ï¼ŒCypher æŸ¥è¯¢ |
| æµå¼è¾“å‡º | FastAPI SSE | StreamingResponse + get_stream_writer() |

---

## äºŒã€LangGraph å·¥ä½œæµæ¶æ„

### 2.1 å·¥ä½œæµå›¾ï¼ˆMermaidï¼‰

```mermaid
graph TB
    START(("START")) --> route_entry{"å…¥å£è·¯ç”±"}
    
    route_entry -->|"æ·±åº¦åˆ†æ"| deep_analysis_node["æ·±åº¦åˆ†æèŠ‚ç‚¹"]
    route_entry -->|"éœ€è¦æ‘˜è¦"| summarize_conversation["å¯¹è¯æ‘˜è¦èŠ‚ç‚¹"]
    route_entry -->|"ä¸šåŠ¡è§„åˆ™"| update_memory["è®°å¿†æ›´æ–°èŠ‚ç‚¹"]
    route_entry -->|"æ™®é€šå¯¹è¯"| context_node["ä¸Šä¸‹æ–‡æ„å»ºèŠ‚ç‚¹"]
    
    deep_analysis_node --> END1(("END"))
    summarize_conversation --> context_node
    update_memory --> END2(("END"))
    
    context_node --> understand_node["æ·±åº¦ç†è§£èŠ‚ç‚¹"]
    understand_node --> route_complexity{"å¤æ‚åº¦è·¯ç”±"}
    
    route_complexity -->|"standard"| reason_node["æ¨ç†å›ç­”èŠ‚ç‚¹"]
    route_complexity -->|"complex"| plan_node["ä»»åŠ¡è§„åˆ’èŠ‚ç‚¹"]
    
    reason_node --> route_tools{"å·¥å…·è·¯ç”±"}
    route_tools -->|"æœ‰å·¥å…·è°ƒç”¨"| tool_node["å·¥å…·èŠ‚ç‚¹"]
    route_tools -->|"æ— å·¥å…·è°ƒç”¨"| END3(("END"))
    tool_node --> reason_node
    
    plan_node --> step_node["æ­¥éª¤æ‰§è¡ŒèŠ‚ç‚¹"]
    step_node --> route_step{"æ­¥éª¤è·¯ç”±"}
    route_step -->|"ç»§ç»­æ‰§è¡Œ"| step_node
    route_step -->|"è¿›å…¥ç»¼åˆ"| synthesize_node["ç»¼åˆè¾“å‡ºèŠ‚ç‚¹"]
    synthesize_node --> END4(("END"))
```

### 2.2 åŒè·¯å¾„è®¾è®¡

| è·¯å¾„ | é€‚ç”¨åœºæ™¯ | èŠ‚ç‚¹æµç¨‹ | å…¸å‹è€—æ—¶ |
|------|----------|----------|----------|
| **Standard** | ç®€å•é—®é¢˜ï¼ˆå•ä¸€æ„å›¾ã€å•æ¬¡å·¥å…·è°ƒç”¨ï¼‰ | context â†’ understand â†’ reason â†’ tool â†º â†’ END | 1-3s |
| **Complex** | å¤æ‚é—®é¢˜ï¼ˆå¤šæ„å›¾ã€å¤šæ­¥éª¤ã€å¯¹æ¯”åˆ†æï¼‰ | context â†’ understand â†’ plan â†’ step â†º â†’ synthesize â†’ END | 5-15s |

---

## ä¸‰ã€çŠ¶æ€å®šä¹‰ï¼ˆState Schemaï¼‰

### 3.1 æ ¸å¿ƒçŠ¶æ€ç»“æ„

```python
# /app/agent/core/schemas.py

class ConversationState(MessagesState):
    """å¯¹è¯çŠ¶æ€ - ç»§æ‰¿å®˜æ–¹ MessagesState"""
    
    # å¢å¼ºä¸Šä¸‹æ–‡ï¼ˆcontext_node å†™å…¥ï¼‰
    enriched_context: NotRequired[EnrichedContext]
    
    # ç”¨æˆ·è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆcontext_node å†™å…¥ï¼Œv3.8 æ–°å¢ï¼‰
    user_memory_context: NotRequired[UserMemoryContext]
    
    # ç†è§£ç»“æœï¼ˆunderstand_node å†™å…¥ï¼‰
    understanding: NotRequired[UnderstandingResult]
    
    # æ‰§è¡Œè®¡åˆ’ï¼ˆplan_node å†™å…¥ï¼ŒComplex è·¯å¾„ï¼‰
    execution_plan: NotRequired[ExecutionPlan]
    
    # ä¸­é—´ç»“æœï¼ˆstep_node è¿½åŠ ï¼ŒComplex è·¯å¾„ï¼‰
    intermediate_results: NotRequired[List[IntermediateResult]]
```

### 3.2 å…³é”®ç±»å‹å®šä¹‰

```python
class UnderstandingResult(TypedDict):
    """understand_node è¾“å‡º"""
    intent: Literal["query_data", "analyze_trend", "compare", "optimize", "general_qa"]
    high_level_goal: str                    # ä¸€å¥è¯ä»»åŠ¡æè¿°
    entities: ExtractedEntities             # æå–çš„å®ä½“
    complexity: Literal["standard", "complex"]
    complexity_reason: str
    requires_data: bool
    sub_questions: List[str]                # ä»… complex æ—¶å¡«å……
    followup_suggestions: List[str]         # LLM å»ºè®®

class ExecutionPlan(TypedDict):
    """plan_node è¾“å‡º"""
    goal: str
    steps: List[PlanStep]
    current_step_index: int
    max_steps: int                          # é˜²æ­»å¾ªç¯ï¼Œé»˜è®¤5
    status: Literal["planning", "executing", "completed", "failed"]

class PlanStep(TypedDict):
    """æ‰§è¡Œè®¡åˆ’æ­¥éª¤"""
    id: str
    description: str
    action: Literal["query", "analyze", "compare", "synthesize"]
    tool_name: Optional[str]
    tool_args: Optional[Dict[str, Any]]
    depends_on: List[str]
    status: Literal["pending", "running", "completed", "failed"]
```

### 3.3 è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼ˆcontext_schemaï¼‰

```python
@dataclass
class WarehouseContextSchema:
    """é™æ€è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ - invoke() æ—¶ä¼ å…¥"""
    user_id: str = "default"
    session_id: str = "default"
    warehouse_code: Optional[str] = None
    warehouse_name: Optional[str] = None
```

---

## å››ã€èŠ‚ç‚¹è¯¦è§£

### 4.1 èŠ‚ç‚¹æ€»è§ˆ

| èŠ‚ç‚¹ | æ–‡ä»¶ | è¡Œæ•° | èŒè´£ | è·¯å¾„ |
|------|------|------|------|------|
| `context_node` | nodes/context_node.py | 670 | ä¸Šä¸‹æ–‡æ„å»º + ç”¨æˆ·è®°å¿†åŠ è½½ | å…±ç”¨ |
| `understand_node` | conversation_agent/nodes/understand_node.py | 933 | æ„å›¾è¯†åˆ« + å®ä½“æå– + å¤æ‚åº¦è¯„ä¼° | å…±ç”¨ |
| `reason_node` | conversation_agent/nodes/reason_node.py | 525 | CoT æ¨ç† + å·¥å…·è°ƒç”¨ | Standard |
| `plan_node` | conversation_agent/nodes/plan_node.py | 1236 | ä»»åŠ¡è§„åˆ’ + æ‰§è¡Œè®¡åˆ’ç”Ÿæˆ | Complex |
| `step_node` | conversation_agent/nodes/step_node.py | 761 | æ­¥éª¤æ‰§è¡Œï¼ˆå¾ªç¯ï¼‰ | Complex |
| `synthesize_node` | conversation_agent/nodes/synthesize_node.py | 475 | ç»“æœæ±‡æ€» + æœ€ç»ˆå›ç­” | Complex |
| `deep_analysis_node` | conversation_agent/nodes/deep_analysis_node.py | 2782 | ç¯èŠ‚/ç­ç»„æ·±åº¦åˆ†æ | ç‰¹æ®Šè§¦å‘ |
| `tool_node` | LangGraph ToolNode | - | å·¥å…·æ‰§è¡Œ | Standard |
| `summarize_conversation` | nodes/conversation_summary_node.py | 391 | å¯¹è¯å†å²å‹ç¼© | ç³»ç»Ÿçº§ |
| `update_memory` | nodes/update_memory_node.py | 648 | ä¸šåŠ¡è§„åˆ™ç®¡ç† + HITL | HITL |

---

### 4.2 context_nodeï¼ˆä¸Šä¸‹æ–‡æ„å»ºèŠ‚ç‚¹ï¼‰

**æ–‡ä»¶**: `/app/agent/nodes/context_node.py`

**èŒè´£**:
1. ä» `runtime.context` è·å–ä»“åº“é™æ€ä¸Šä¸‹æ–‡
2. ä»æ¶ˆæ¯ä¸­æå–ä»“åº“è¦†ç›–
3. ä»ç¼“å­˜åŠ è½½ä»“åº“åŸºæœ¬ä¿¡æ¯
4. å‘é‡çŸ¥è¯†æ£€ç´¢ï¼ˆå¼‚æ­¥ï¼‰
5. **v3.8 æ–°å¢**ï¼šç”¨æˆ·è®°å¿†åŠ è½½ä¸æ³¨å…¥

**æ ¸å¿ƒæŠ€æœ¯å®ç°**:

```python
async def async_context_node(state, *, runtime):
    # 1. è·å–é™æ€ä¸Šä¸‹æ–‡
    warehouse_code = runtime.context.warehouse_code
    user_id = runtime.context.user_id
    
    # 2. ä»æ¶ˆæ¯è¯†åˆ«ä»“åº“è¦†ç›–
    message_warehouse = extract_warehouse_from_message(current_message)
    
    # 3. ç”¨æˆ·è®°å¿†åŠ è½½ï¼ˆæ ¹æ®æ¶ˆæ¯å†³å®šç­–ç•¥ï¼‰
    memory_strategy = MemoryRouter.determine_strategy(current_message)
    user_memory_context = await _load_user_memory(runtime.store, user_id, memory_strategy)
    
    # 4. å¼‚æ­¥å‘é‡çŸ¥è¯†æ£€ç´¢
    retrieved_knowledge = await async_load_warehouse_knowledge(
        runtime.store, warehouse_code, current_message, limit=5
    )
    
    # 5. æ„å»º system_prompt + æ³¨å…¥ç”¨æˆ·è®°å¿†
    system_prompt = build_dynamic_system_prompt(...)
    user_aware_section = _build_user_aware_prompt_section(user_memory_context)
    
    return {
        "enriched_context": enriched_context,
        "user_memory_context": user_memory_context
    }
```

**è®°å¿†åŠ è½½ç­–ç•¥**:
- `STANDARD`: profile + activityï¼ˆå¤§å¤šæ•°åœºæ™¯ï¼‰
- `FULL`: profile + activity + historyï¼ˆæ¶‰åŠå†å²/è¶‹åŠ¿æ—¶ï¼‰

---

### 4.3 understand_nodeï¼ˆæ·±åº¦ç†è§£èŠ‚ç‚¹ï¼‰

**æ–‡ä»¶**: `/app/agent/agents/conversation_agent/nodes/understand_node.py`

**èŒè´£**:
1. æ„å›¾è¯†åˆ«ï¼ˆ5ç±»ï¼‰
2. å®ä½“æå–ï¼ˆä»“åº“ã€æ—¶é—´ã€æ–¹å‘ã€æŒ‡æ ‡ï¼‰
3. **å¤æ‚åº¦è¯„ä¼°**ï¼ˆå†³å®šè·¯ç”±ï¼‰
4. v3.7 æ–°å¢ï¼šhigh_level_goal + followup_suggestions

**æ··åˆç­–ç•¥**:
- **è§„åˆ™å±‚**ï¼šå¿«é€Ÿå…³é”®è¯/æ¨¡å¼åŒ¹é…
- **LLM å±‚**ï¼šç»“æ„åŒ–è¾“å‡ºï¼ˆPydantic Schemaï¼‰

**å¤æ‚åº¦åˆ¤æ–­è§„åˆ™**:

```python
# è§„åˆ™å±‚å¿«é€Ÿåˆ¤æ–­
COMPLEX_KEYWORDS = [
    "å¯¹æ¯”", "æ¯”è¾ƒ", "åˆ†æ", "è¶‹åŠ¿", "å˜åŒ–", "ä¼˜åŒ–", "è§„åˆ’",
    "ä¸ºä»€ä¹ˆ", "å¦‚ä½•æ”¹è¿›", "å»ºè®®", "æŠ¥å‘Š", "å†å²", "ç“¶é¢ˆ"
]

COMPLEX_PATTERNS = [
    r"å¯¹æ¯”.+å’Œ.+",           # å¯¹æ¯” A å’Œ B
    r"åˆ†æ.+è¶‹åŠ¿",           # åˆ†æ X è¶‹åŠ¿
    r"ä¸ºä»€ä¹ˆ.+(ä½|é«˜|æ…¢|å¿«)",  # æ ¹å› åˆ†æ
]

def quick_complexity_check(message: str) -> Optional[str]:
    # çŸ­æ¶ˆæ¯ + æ— å¤æ‚å…³é”®è¯ = standard
    if len(message) < 30 and not any(kw in message for kw in COMPLEX_KEYWORDS):
        return "standard"
    
    # 2+ å¤æ‚å…³é”®è¯ = complex
    if sum(1 for kw in COMPLEX_KEYWORDS if kw in message) >= 2:
        return "complex"
    
    # è§„åˆ™æ— æ³•ç¡®å®š â†’ LLM åˆ¤æ–­
    return None
```

**LLM ç»“æ„åŒ–è¾“å‡ºï¼ˆv3.7 with_structured_outputï¼‰**:

```python
class UnderstandingSchema(BaseModel):
    intent: Literal["query_data", "analyze_trend", "compare", "optimize", "general_qa"]
    high_level_goal: str = Field(min_length=5, max_length=200)
    complexity: Literal["standard", "complex"]
    requires_data: bool
    followup_suggestions: List[str] = Field(default_factory=list)
    
    @field_validator("high_level_goal")
    def validate_goal(cls, v):
        # è¿‡æ»¤æ— æ„ä¹‰çš„é»˜è®¤å€¼
        invalid_defaults = ["å›ç­”ç”¨æˆ·çš„é—®é¢˜", "å¤„ç†ç”¨æˆ·è¯·æ±‚"]
        if v.strip() in invalid_defaults:
            raise ValueError("high_level_goal ä¸èƒ½æ˜¯é»˜è®¤å€¼")
        return v.strip()

# ä½¿ç”¨ with_structured_output ç»‘å®š Schema
structured_model = qwen_fast.with_structured_output(
    UnderstandingSchema,
    method="function_calling"
)
```

**æ¨¡å‹é€‰æ‹©**:
- ä½¿ç”¨ `qwen_fast`ï¼ˆqwen-turbo, temperature=0, max_tokens=200ï¼‰
- å¿«é€Ÿã€ç¡®å®šæ€§è¾“å‡ºï¼Œä¸“æ³¨è·¯ç”±åˆ¤æ–­

---

### 4.4 reason_nodeï¼ˆæ¨ç†å›ç­”èŠ‚ç‚¹ - Standard è·¯å¾„ï¼‰

**æ–‡ä»¶**: `/app/agent/agents/conversation_agent/nodes/reason_node.py`

**èŒè´£**:
1. è¯»å– understanding + enriched_context
2. åŸºäºæ„å›¾æ„å»ºä¸“ç”¨ CoT æç¤º
3. å·¥å…·è°ƒç”¨å†³ç­–
4. **v3.9 æ–°å¢**ï¼šå·¥å…·ä½¿ç”¨è®°å½•

**æ„å›¾ä¸“ç”¨ CoT æ¨¡æ¿**:

```python
INTENT_SPECIFIC_COT_TEMPLATES = {
    "query_data": """
## ğŸ§  æ•°æ®æŸ¥è¯¢æ¨ç†æ¡†æ¶
### æŸ¥è¯¢æ€è€ƒè¿‡ç¨‹
1. **è¯†åˆ«æ•°æ®ç»´åº¦**ï¼šä»“åº“ã€æ—¶é—´èŒƒå›´ã€ä¸šåŠ¡æ–¹å‘ã€ç¯èŠ‚
2. **é€‰æ‹©æŸ¥è¯¢å·¥å…·**ï¼šæ ¹æ®ç»´åº¦é€‰æ‹©åˆé€‚çš„å·¥å…·
3. **è§£ææŸ¥è¯¢ç»“æœ**ï¼šæå–å…³é”®æ•°æ®å­—æ®µ
4. **æ ¼å¼åŒ–è¾“å‡º**ï¼šä½¿ç”¨è¡¨æ ¼å±•ç¤ºå¯¹æ¯”æ•°æ®

### âš ï¸ æ•°æ®æŸ¥è¯¢çº¦æŸ
- **ä¸¥ç¦ç¼–é€ æ•°æ®**ï¼šæ‰€æœ‰æ•°æ®å¿…é¡»æ¥è‡ªå·¥å…·è°ƒç”¨ç»“æœ
""",
    
    "analyze_trend": """...""",
    "compare": """...""",
    "optimize": """...""",
    "general_qa": """...""",
}
```

**å·¥å…·è°ƒç”¨å¾ªç¯**:
```
reason_node â†’ tool_calls? â†’ tool_node â†’ reason_node â†’ ... â†’ END
```

---

### 4.5 plan_nodeï¼ˆä»»åŠ¡è§„åˆ’èŠ‚ç‚¹ - Complex è·¯å¾„ï¼‰

**æ–‡ä»¶**: `/app/agent/agents/conversation_agent/nodes/plan_node.py`

**èŒè´£**:
1. è¯»å– understandingï¼ˆå¤æ‚é—®é¢˜åˆ†æï¼‰
2. åŠ¨æ€æ³¨å…¥å·¥å…·åˆ—è¡¨åˆ°æç¤ºè¯
3. ä½¿ç”¨ LLM ç”Ÿæˆç»“æ„åŒ–æ‰§è¡Œè®¡åˆ’
4. éªŒè¯å¹¶è§„èŒƒåŒ–è®¡åˆ’

**åŠ¨æ€å·¥å…·æ³¨å…¥**:

```python
def create_plan_node(model=None, tools: List[BaseTool] = None):
    # åŠ¨æ€ç”Ÿæˆå·¥å…·æè¿°
    tool_descriptions = _generate_tool_descriptions(tools)
    graph_schema = _get_graph_schema_for_planning()
    
    dynamic_system_prompt = PLANNING_PROMPT.format(
        tool_descriptions=tool_descriptions,
        graph_schema=graph_schema
    )
```

**æ‰§è¡Œè®¡åˆ’ç¤ºä¾‹**:

```json
{
  "goal": "åˆ†æåå—ä¸œèæ–°é©¬é›†è¿ä»“ä½œä¸šç¯èŠ‚çš„ä¾èµ–å…³ç³»",
  "steps": [
    {
      "id": "step_1",
      "description": "è·å–ä»“åº“æ‰€æœ‰ä½œä¸šç¯èŠ‚",
      "action": "query",
      "tool_name": "get_warehouse_stages",
      "tool_args": {"warehouse_id": "20142001"},
      "depends_on": []
    },
    {
      "id": "step_2",
      "description": "æŸ¥è¯¢ä¸Šæ¶ç¯èŠ‚ä¸Šä¸‹æ¸¸ä¾èµ–",
      "action": "query",
      "tool_name": "get_stage",
      "tool_args": {"stage_id": "20142001_shelving_stage", "include_upstream": true},
      "depends_on": ["step_1"]
    },
    {
      "id": "step_3",
      "description": "ç»¼åˆåˆ†æç¯èŠ‚ä¾èµ–å…³ç³»",
      "action": "synthesize",
      "depends_on": ["step_2"]
    }
  ]
}
```

**Action ç±»å‹**:
- `query`: è°ƒç”¨å·¥å…·æŸ¥è¯¢æ•°æ®
- `analyze`: LLM åˆ†ææ•°æ®
- `compare`: LLM å¯¹æ¯”åˆ†æ
- `synthesize`: ç»¼åˆç”Ÿæˆæœ€ç»ˆå›ç­”

---

### 4.6 step_nodeï¼ˆæ­¥éª¤æ‰§è¡ŒèŠ‚ç‚¹ - Complex è·¯å¾„ï¼‰

**æ–‡ä»¶**: `/app/agent/agents/conversation_agent/nodes/step_node.py`

**èŒè´£**:
1. è¯»å– execution_plan.current_step_index
2. æ ¹æ® action ç±»å‹æ‰§è¡Œå¯¹åº”æ“ä½œ
3. å°†ç»“æœè¿½åŠ åˆ° intermediate_results
4. æ›´æ–°æ­¥éª¤çŠ¶æ€å’Œç´¢å¼•
5. **v3.9 æ–°å¢**ï¼šå·¥å…·ä½¿ç”¨è®°å½•

**å¾ªç¯æ‰§è¡Œæœºåˆ¶**:

```python
def route_step(state) -> str:
    execution_plan = state.get("execution_plan")
    current_index = execution_plan.get("current_step_index", 0)
    steps = execution_plan.get("steps", [])
    max_steps = execution_plan.get("max_steps", 5)
    
    # ç»ˆæ­¢æ¡ä»¶
    if current_index >= len(steps) or current_index >= max_steps:
        return "synthesize_node"
    
    # ä¸‹ä¸€æ­¥æ˜¯ synthesize
    if steps[current_index].get("action") == "synthesize":
        return "synthesize_node"
    
    return "step_node"  # ç»§ç»­å¾ªç¯
```

**å·¥å…·æ‰§è¡Œä¼˜åŒ–ï¼ˆv3.3ï¼‰**:

```python
# O(1) å­—å…¸æŸ¥æ‰¾ï¼ˆæ›¿ä»£ O(n) çº¿æ€§æœç´¢ï¼‰
tool_map = {getattr(t, 'name', ''): t for t in available_tools}

async def _execute_tool(tool_name, tool_args, tool_map):
    tool = tool_map.get(tool_name)
    if not tool:
        return {"success": False, "error": f"å·¥å…· {tool_name} ä¸å­˜åœ¨"}
    return await tool.ainvoke(tool_args)
```

---

### 4.7 synthesize_nodeï¼ˆç»¼åˆè¾“å‡ºèŠ‚ç‚¹ - Complex è·¯å¾„ï¼‰

**æ–‡ä»¶**: `/app/agent/agents/conversation_agent/nodes/synthesize_node.py`

**èŒè´£**:
1. è¯»å– intermediate_results
2. æ ¼å¼åŒ–ä¸­é—´ç»“æœä¾› LLM ç»¼åˆ
3. **v3.10 æ–°å¢**ï¼šæ¶ˆè´¹ç”¨æˆ·å®Œæ•´è®°å¿†
4. ç”Ÿæˆç”¨æˆ·å‹å¥½çš„æœ€ç»ˆå›ç­”

**ç”¨æˆ·è®°å¿†æ¶ˆè´¹ï¼ˆv3.10ï¼‰**:

```python
def _format_user_context(state):
    user_memory = state.get("user_memory_context")
    if user_memory:
        # 1. ç”¨æˆ·åå¥½ï¼ˆå¿…é¡»éµå¾ªï¼‰
        preferences = user_memory.get("profile", {}).get("preferences", [])
        
        # 2. é«˜é¢‘æ“ä½œï¼ˆä¾›å‚è€ƒï¼‰
        frequent_actions = user_memory.get("activity", {}).get("frequent_actions", [])
        
        # 3. å†å²å¯¹è¯ï¼ˆä¾›å‚è€ƒï¼‰
        history_entries = user_memory.get("history", {}).get("entries", [])
```

---

## äº”ã€è·¯ç”±é€»è¾‘

### 5.1 å…¥å£è·¯ç”±ï¼ˆroute_entryï¼‰

```python
def route_entry(state):
    """
    è·¯ç”±ä¼˜å…ˆçº§ï¼š
    1. æ·±åº¦åˆ†æè§¦å‘ï¼ˆmessage_kwargs.type == "deep_analysis"ï¼‰
    2. å¯¹è¯æ‘˜è¦æ£€æŸ¥ï¼ˆtoken/æ¶ˆæ¯æ•°é˜ˆå€¼ï¼‰
    3. ä¸šåŠ¡è§„åˆ™ç®¡ç†å…³é”®è¯
    4. é»˜è®¤ï¼šæ™®é€šå¯¹è¯
    """
    # 1. æ·±åº¦åˆ†æ
    if msg_type == "deep_analysis":
        return "deep_analysis_node"
    
    # 2. æ‘˜è¦
    if should_summarize_conversation(state) == "summarize":
        return "summarize_conversation"
    
    # 3. ä¸šåŠ¡è§„åˆ™
    memory_keywords = ["æ·»åŠ ä¸šåŠ¡è§„åˆ™", "æ·»åŠ è§„åˆ™", "ä¿å­˜è§„åˆ™"]
    if any(kw in content for kw in memory_keywords):
        return "update_memory"
    
    # 4. é»˜è®¤
    return "context_node"
```

### 5.2 å¤æ‚åº¦è·¯ç”±ï¼ˆroute_complexityï¼‰

```python
def route_complexity(state):
    understanding = state.get("understanding")
    complexity = understanding.get("complexity", "standard")
    
    if complexity == "complex":
        return "plan_node"    # Complex è·¯å¾„
    return "reason_node"      # Standard è·¯å¾„
```

### 5.3 å·¥å…·è·¯ç”±ï¼ˆroute_toolsï¼‰

```python
def route_tools(state):
    last_message = state["messages"][-1]
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tool_node"
    return END
```

---

## å…­ã€å·¥å…·é›†

### 6.1 æ•°æ®æŸ¥è¯¢å·¥å…·

| å·¥å…·å | åŠŸèƒ½ | æ•°æ®èŒƒå›´ |
|--------|------|----------|
| `query_orders_data_by_date_range` ğŸ”¥ | ç»Ÿä¸€æŸ¥è¯¢é¢„æµ‹/å®é™…/ç»¼åˆæ•°æ® | ä»“åº“çº§åˆ« |
| `query_single_day_hourly_distribution_tool` | å•æ—¥24å°æ—¶æµé€Ÿåˆ†å¸ƒ | ç¯èŠ‚çº§åˆ« |
| `query_multi_day_hourly_distribution_tool` | Nå¤©å¹³å‡æµé€Ÿåˆ†å¸ƒ | ç¯èŠ‚çº§åˆ« |
| `predict_hourly_distribution_tool` | å°æ—¶çº§é¢„æµ‹ | ç¯èŠ‚çº§åˆ« |

### 6.2 çŸ¥è¯†å›¾è°±å·¥å…·ï¼ˆ18ä¸ªï¼‰

| ç±»åˆ« | å·¥å…· | åŠŸèƒ½ |
|------|------|------|
| åŸºç¡€æŸ¥è¯¢ | `get_warehouse_info`, `get_warehouse_stages` | ä»“åº“/ç¯èŠ‚åŸºç¡€ä¿¡æ¯ |
| ç»Ÿä¸€æŸ¥è¯¢ | `get_stage` ğŸ”¥ | ç¯èŠ‚å¤šç»´åº¦æŸ¥è¯¢ï¼ˆçŠ¶æ€/ä¾èµ–/ç­ç»„ï¼‰ |
| å®æ—¶çŠ¶æ€ | `get_stage_current_status`, `get_warehouse_realtime_overview` | å®æ—¶å¿«ç…§ |
| ç­ç»„çŠ¶æ€ | `get_team`, `get_warehouse_work_groups` | ç­ç»„ä¿¡æ¯ä¸çŠ¶æ€ |
| ä»“åº“æ±‡æ€» | `get_warehouse_overview` ğŸ”¥ | å…¨æ™¯è§†å›¾ + æ™ºèƒ½åˆ†æ |
| æ™ºèƒ½åˆ†æ | `detect_stage_anomalies`, `generate_allocation_suggestion` | å¼‚å¸¸æ£€æµ‹/è°ƒåº¦å»ºè®® |

---

## ä¸ƒã€å­˜å‚¨å±‚æ¶æ„

### 7.1 PostgreSQLManager å•ä¾‹

```python
class PostgreSQLManager:
    """å…¨å±€è¿æ¥æ± ç®¡ç†"""
    
    async def initialize(self):
        # 1. åˆ›å»º AsyncConnectionPool
        self._connection_pool = AsyncConnectionPool(
            min_size=5, max_size=20,
            timeout=30, max_idle=300, max_lifetime=1800
        )
        
        # 2. åˆ›å»º Checkpointerï¼ˆçŸ­æœŸè®°å¿†ï¼‰
        self._checkpointer = AsyncPostgresSaver(self._connection_pool)
        await self._checkpointer.setup()
        
        # 3. åˆ›å»º Storeï¼ˆé•¿æœŸè®°å¿† + å‘é‡ç´¢å¼•ï¼‰
        self._store = AsyncPostgresStore(self._connection_pool, index=vector_config)
        await self._store.setup()
```

### 7.2 è®°å¿†ç³»ç»Ÿå‘½åç©ºé—´

| ç±»å‹ | å‘½åç©ºé—´ | å­˜å‚¨å†…å®¹ |
|------|----------|----------|
| çŸ­æœŸè®°å¿† | `thread_id` | å¯¹è¯å†å²ã€çŠ¶æ€å¿«ç…§ |
| ç”¨æˆ·ç”»åƒ | `("user_profile", user_id)` | åå¥½ã€ç®¡ç†ä»“åº“ |
| ç”¨æˆ·æ´»åŠ¨ | `("user_activity", user_id)` | è¡Œä¸ºæ˜ç»†ã€é«˜é¢‘æ“ä½œ |
| å†å²å¯¹è¯ | `("conversation_history", user_id)` | ä¼šè¯æ‘˜è¦ |
| ä»“åº“è§„åˆ™ | `("warehouse_rules", code)` | ä¸šåŠ¡è§„åˆ™ |

---

## å…«ã€æµå¼è¾“å‡ºæœºåˆ¶

### 8.1 get_stream_writer() å®æ—¶è¿›åº¦

```python
# èŠ‚ç‚¹å†…éƒ¨ä½¿ç”¨
from langgraph.config import get_stream_writer

async def step_node(state, *, runtime):
    writer = get_stream_writer()
    
    # å‘é€è¿›åº¦
    writer({
        "type": "process",
        "node": "step_node",
        "content": "> ğŸ” æ‰§è¡Œæ­¥éª¤ 1/3: æŸ¥è¯¢æ•°æ®...\n\n",
        "timestamp": datetime.now(timezone.utc).isoformat()
    })
```

### 8.2 stream_mode ç»„åˆ

```python
async for stream_mode, chunk in graph.astream(
    input,
    config,
    stream_mode=["custom", "messages"]  # custom: è¿›åº¦, messages: token
):
    if stream_mode == "custom":
        # èŠ‚ç‚¹è¿›åº¦
        yield chunk
    elif stream_mode == "messages":
        # LLM token
        message_chunk, metadata = chunk
        if isinstance(message_chunk, AIMessageChunk):
            yield {"type": "token", "content": message_chunk.content}
```

---

## ä¹ã€é‡è¯•ç­–ç•¥é…ç½®

```python
# æ‰€æœ‰èŠ‚ç‚¹é…ç½®é‡è¯•ç­–ç•¥
UNDERSTAND_NODE_RETRY_POLICY = RetryPolicy(
    max_attempts=2,
    initial_interval=0.5,
    backoff_factor=2.0,
    jitter=True,
    retry_on=Exception
)

REASON_NODE_RETRY_POLICY = RetryPolicy(
    max_attempts=3,
    initial_interval=1.0,
    backoff_factor=2.0,
    jitter=True
)

# ToolNode è‡ªå®šä¹‰é”™è¯¯å¤„ç†
tool_node = ToolNode(
    tools,
    handle_tool_errors=handle_tool_error  # é”™è¯¯è½¬å‹å¥½ä¿¡æ¯ç»™ LLM
)
```

---

## åã€å·²çŸ¥é—®é¢˜ä¸ä¼˜åŒ–æ–¹å‘

### 10.1 å½“å‰å·²çŸ¥é—®é¢˜

1. **å¤æ‚åº¦è¯¯åˆ¤**ï¼šç®€å•é—®å€™å¯èƒ½è¢«åˆ¤ä¸º complex
   - åŸå› ï¼šunderstand_node æç¤ºè¯è¿‡æ‹Ÿåˆä¸šåŠ¡
   - çŠ¶æ€ï¼šv3.11 å·²ä¼˜åŒ–æç¤ºè¯ï¼Œå¢åŠ ä¸‰å±‚é˜²æŠ¤

2. **Complex è·¯å¾„å»¶è¿Ÿ**ï¼šplan + step + synthesize è€—æ—¶è¾ƒé•¿
   - æ–¹å‘ï¼šè€ƒè™‘å¹¶è¡Œæ­¥éª¤æ‰§è¡Œ

### 10.2 ä¼˜åŒ–æ–¹å‘å»ºè®®

| æ–¹å‘ | æè¿° | ä¼˜å…ˆçº§ |
|------|------|--------|
| **æ­¥éª¤å¹¶è¡ŒåŒ–** | step_node æ”¯æŒæ— ä¾èµ–æ­¥éª¤å¹¶è¡Œæ‰§è¡Œ | P1 |
| **ç¼“å­˜ä¼˜åŒ–** | çƒ­ç‚¹æ•°æ® Redis ç¼“å­˜ | P1 |
| **æ„å›¾åˆ†ç±»æ¨¡å‹** | è®­ç»ƒè½»é‡åˆ†ç±»æ¨¡å‹æ›¿ä»£ LLM | P2 |
| **å·¥å…·è°ƒç”¨åˆå¹¶** | è¯†åˆ«å¯åˆå¹¶çš„å·¥å…·è°ƒç”¨ | P2 |
| **å¤š Agent åä½œ** | æ‹†åˆ†ä¸ºå¤šä¸ªä¸“ä¸šå­ Agent | P3 |

---

## åä¸€ã€æ–‡ä»¶æ¸…å•

### conversation_agent æ¨¡å—

| æ–‡ä»¶ | è¡Œæ•° | èŒè´£ |
|------|------|------|
| production_conversation_agent.py | 1643 | ä¸» Agent ç±» |
| prompts/system_prompt.py | 440 | ç³»ç»Ÿæç¤ºè¯æ„å»º |
| utils/warehouse_context.py | ~150 | ä»“åº“ä¸Šä¸‹æ–‡ |
| utils/knowledge_loader.py | ~250 | çŸ¥è¯†æ£€ç´¢ |
| **nodes/** | | |
| understand_node.py | 933 | æ·±åº¦ç†è§£ |
| reason_node.py | 525 | æ¨ç†å›ç­” |
| plan_node.py | 1236 | ä»»åŠ¡è§„åˆ’ |
| step_node.py | 761 | æ­¥éª¤æ‰§è¡Œ |
| synthesize_node.py | 475 | ç»¼åˆè¾“å‡º |
| deep_analysis_node.py | 2782 | æ·±åº¦åˆ†æ |

### å…¨å±€æ¨¡å—

| æ–‡ä»¶ | è¡Œæ•° | èŒè´£ |
|------|------|------|
| core/schemas.py | 521 | State Schema |
| core/models.py | ~210 | LLM æ¨¡å‹é…ç½® |
| nodes/context_node.py | 670 | ä¸Šä¸‹æ–‡æ„å»º |
| nodes/conversation_summary_node.py | 391 | å¯¹è¯æ‘˜è¦ |
| nodes/update_memory_node.py | 648 | HITL è§„åˆ™ç®¡ç† |
| storage/postgres_manager.py | 463 | PostgreSQL ç®¡ç† |
| tools/orders_data.py | ~500 | æ•°æ®æŸ¥è¯¢å·¥å…· |
| tools/hour_data_tools.py | 762 | å°æ—¶çº§æ•°æ®å·¥å…· |
| kg_agent/tool/kg_tool.py | 3304 | 18ä¸ªKGå·¥å…· |

---

## åäºŒã€é™„å½•ï¼šå…³é”®ä»£ç ç‰‡æ®µ

### A. å·¥ä½œæµç¼–è¯‘

```python
# production_conversation_agent.py

async def _compile_graph(self):
    workflow = StateGraph(
        ConversationState,
        context_schema=WarehouseContextSchema
    )
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("context_node", context_node, retry=...)
    workflow.add_node("understand_node", understand_node, retry=...)
    workflow.add_node("reason_node", reason_node, retry=...)
    workflow.add_node("plan_node", plan_node, retry=...)
    workflow.add_node("step_node", step_node, retry=...)
    workflow.add_node("synthesize_node", synthesize_node, retry=...)
    workflow.add_node("tool_node", tool_node, retry=...)
    
    # é…ç½®è·¯ç”±è¾¹
    workflow.add_conditional_edges(START, route_entry, {...})
    workflow.add_conditional_edges("understand_node", route_complexity, {...})
    workflow.add_conditional_edges("reason_node", route_tools, {...})
    workflow.add_conditional_edges("step_node", route_step, {...})
    
    # ç¼–è¯‘
    self.compiled_graph = workflow.compile(
        checkpointer=self.checkpointer,
        store=self.store,
        debug=True
    )
```

### B. æµå¼è°ƒç”¨

```python
async def stream_chat(self, message, user_id, session_id, warehouse_code):
    async for stream_mode, chunk in self.compiled_graph.astream(
        {"messages": [HumanMessage(content=message)]},
        config,
        context=context,
        stream_mode=["custom", "messages"]
    ):
        if stream_mode == "custom":
            yield chunk  # èŠ‚ç‚¹è¿›åº¦
        elif stream_mode == "messages":
            message_chunk, metadata = chunk
            if isinstance(message_chunk, AIMessageChunk):
                yield {"type": "token", "content": message_chunk.content}
```

---

**æ–‡æ¡£ç»“æŸ**

å¦‚éœ€è¿›ä¸€æ­¥è®¨è®ºå…·ä½“èŠ‚ç‚¹çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿã€‚
