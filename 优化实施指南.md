# Conversation Agent ä¼˜åŒ–å®æ–½æŒ‡å—

> **åŸºäº**: Moltbotæ¶æ„åˆ†æ + æŠ€æœ¯è®¨è®º  
> **ç›®æ ‡**: æä¾›å¯ç›´æ¥å®æ–½çš„ä»£ç å’Œæ­¥éª¤

---

## å¿«é€Ÿå¯¼èˆª

| ä¼˜åŒ–é¡¹ | ä¼˜å…ˆçº§ | é¢„è®¡å·¥æœŸ | é¢„æœŸæ”¶ç›Š |
|--------|--------|---------|---------|
| [å·¥å…·å¹¶è¡ŒåŒ–](#1-å·¥å…·å¹¶è¡ŒåŒ–) | P0 | 1å‘¨ | å»¶è¿Ÿé™ä½30-50% |
| [å·¥å…·ç›‘æ§ç³»ç»Ÿ](#2-å·¥å…·ç›‘æ§ç³»ç»Ÿ) | P0 | 3å¤© | å¯è§‚æµ‹æ€§æå‡ |
| [Embeddingç¼“å­˜](#3-embeddingç¼“å­˜) | P0 | 2å¤© | å»¶è¿Ÿé™ä½40% |
| [Traceè¿½è¸ªç³»ç»Ÿ](#4-traceè¿½è¸ªç³»ç»Ÿ) | P1 | 3å¤© | è°ƒè¯•æ•ˆç‡æå‡ |
| [å·¥å…·æƒé™ç­–ç•¥](#5-å·¥å…·æƒé™ç­–ç•¥) | P1 | 1å‘¨ | å®‰å…¨æ€§æå‡ |
| [Skillæ’ä»¶åŒ–](#6-skillæ’ä»¶åŒ–) | P1 | 2å‘¨ | æ‰©å±•æ€§æå‡ |
| [é…ç½®çƒ­é‡è½½](#7-é…ç½®çƒ­é‡è½½) | P2 | 1å‘¨ | è¿ç»´ä¾¿åˆ©æ€§ |
| [Gatewayæ¶æ„](#8-gatewayæ¶æ„) | P2 | 1æœˆ | æ”¯æŒå¤šå¹³å° |

---

## 1. å·¥å…·å¹¶è¡ŒåŒ–

### ç›®æ ‡
- åœ¨step_nodeä¸­å¹¶è¡Œæ‰§è¡Œæ— ä¾èµ–çš„queryæ­¥éª¤
- å»¶è¿Ÿä»Complexè·¯å¾„çš„10-30sé™ä½åˆ°7-18s

### å®Œæ•´å®ç°ä»£ç 

```python
# app/agent/agents/conversation_agent/nodes/step_node_parallel.py

import asyncio
from typing import List, Dict, Any
from langchain_core.tools import BaseTool

async def execute_parallel_steps_optimized(
    state: ConversationState,
    runtime: Any
) -> Dict[str, Any]:
    """
    å¹¶è¡Œæ‰§è¡Œæ­¥éª¤ - ä¼˜åŒ–ç‰ˆ
    
    å…³é”®ä¼˜åŒ–:
    1. æ£€æµ‹æ— ä¾èµ–æ­¥éª¤
    2. å¹¶è¡Œæ‰§è¡Œqueryç±»å‹
    3. é”™è¯¯éš”ç¦»
    4. è¿›åº¦å®æ—¶åé¦ˆ
    """
    execution_plan = state.get("execution_plan", {})
    steps = execution_plan.get("steps", [])
    current_index = execution_plan.get("current_step_index", 0)
    intermediate_results = state.get("intermediate_results", [])
    
    # 1. æ”¶é›†å¯å¹¶è¡Œæ­¥éª¤
    parallel_batch = []
    executed_step_ids = {r["step_id"] for r in intermediate_results}
    
    for i in range(current_index, len(steps)):
        step = steps[i]
        
        # åªæœ‰queryå¯å¹¶è¡Œ
        if step["action"] != "query":
            break
        
        # æ£€æŸ¥ä¾èµ–
        deps = step.get("depends_on", [])
        if all(dep in executed_step_ids for dep in deps):
            parallel_batch.append(step)
        else:
            break  # é‡åˆ°æœ‰ä¾èµ–çš„ï¼Œåœæ­¢æ”¶é›†
    
    if not parallel_batch:
        return state  # æ— å¯å¹¶è¡Œæ­¥éª¤
    
    # 2. æµå¼è¿›åº¦åé¦ˆ
    writer = get_stream_writer()
    writer({
        "type": "process",
        "node": "step_node_parallel",
        "content": f"> ğŸš€ å¹¶è¡Œæ‰§è¡Œ {len(parallel_batch)} ä¸ªæŸ¥è¯¢æ­¥éª¤\n\n"
    })
    
    # 3. æ„å»ºå·¥å…·æ˜ å°„
    available_tools = runtime.tools or []
    tool_map = {getattr(t, 'name', ''): t for t in available_tools}
    
    # 4. å¹¶è¡Œæ‰§è¡Œ
    tasks = []
    for step in parallel_batch:
        task = _execute_single_step(
            step, tool_map, runtime, writer
        )
        tasks.append(task)
    
    # ä½¿ç”¨ asyncio.gather å¹¶è¡Œæ‰§è¡Œ
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # 5. å¤„ç†ç»“æœ
    new_results = []
    for step, result in zip(parallel_batch, results):
        if isinstance(result, Exception):
            # é”™è¯¯å¤„ç†
            new_results.append({
                "step_id": step["id"],
                "description": step["description"],
                "success": False,
                "error": str(result),
                "executed_at": datetime.now(timezone.utc).isoformat()
            })
            
            # æ›´æ–°æ­¥éª¤çŠ¶æ€
            step["status"] = "failed"
        else:
            # æˆåŠŸ
            new_results.append(result)
            step["status"] = "completed"
            
            # v3.9: è®°å½•å·¥å…·ä½¿ç”¨
            if step.get("tool_name"):
                await _record_tool_usage(
                    runtime, step["tool_name"], step.get("tool_args", {})
                )
    
    # 6. æ›´æ–°çŠ¶æ€
    updated_intermediate_results = intermediate_results + new_results
    updated_current_index = current_index + len(parallel_batch)
    
    return {
        "execution_plan": {
            **execution_plan,
            "current_step_index": updated_current_index,
            "steps": steps
        },
        "intermediate_results": updated_intermediate_results
    }

async def _execute_single_step(
    step: Dict,
    tool_map: Dict[str, BaseTool],
    runtime: Any,
    writer: Any
) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
    tool_name = step.get("tool_name")
    tool_args = step.get("tool_args", {})
    
    writer({
        "type": "process",
        "content": f"> ğŸ” {step['description']}\n"
    })
    
    # æŸ¥æ‰¾å·¥å…·
    tool = tool_map.get(tool_name)
    if not tool:
        raise ValueError(f"å·¥å…· {tool_name} æœªæ‰¾åˆ°")
    
    # æ‰§è¡Œå·¥å…·
    start_time = time.time()
    tool_result = await tool.ainvoke(tool_args)
    latency_ms = (time.time() - start_time) * 1000
    
    writer({
        "type": "process",
        "content": f"  âœ… å®Œæˆï¼Œè€—æ—¶ {latency_ms:.0f}ms\n\n"
    })
    
    return {
        "step_id": step["id"],
        "description": step["description"],
        "success": True,
        "result": _convert_to_serializable(tool_result),
        "executed_at": datetime.now(timezone.utc).isoformat(),
        "latency_ms": latency_ms
    }

# ä¿®æ”¹è·¯ç”±è¾¹é…ç½®
workflow.add_edge("plan_node", "step_node_parallel")
workflow.add_conditional_edges(
    "step_node_parallel",
    route_step,  # å¤ç”¨ç°æœ‰è·¯ç”±
    {
        "step_node_parallel": "step_node_parallel",
        "synthesize_node": "synthesize_node"
    }
)
```

### æµ‹è¯•ä»£ç 

```python
# tests/test_parallel_execution.py

import pytest
import asyncio

@pytest.mark.asyncio
async def test_parallel_steps_performance():
    """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œæ€§èƒ½æå‡"""
    
    # æ¨¡æ‹Ÿ3ä¸ªç‹¬ç«‹æŸ¥è¯¢
    steps = [
        {"id": "1", "action": "query", "tool_name": "tool_a", "depends_on": []},
        {"id": "2", "action": "query", "tool_name": "tool_b", "depends_on": []},
        {"id": "3", "action": "query", "tool_name": "tool_c", "depends_on": []},
    ]
    
    # ä¸²è¡Œæ‰§è¡Œ
    start = time.time()
    for step in steps:
        await execute_tool(step["tool_name"])
    serial_time = time.time() - start
    
    # å¹¶è¡Œæ‰§è¡Œ
    start = time.time()
    await asyncio.gather(*[execute_tool(s["tool_name"]) for s in steps])
    parallel_time = time.time() - start
    
    # éªŒè¯åŠ é€Ÿæ¯”
    speedup = serial_time / parallel_time
    assert speedup > 2.5, f"é¢„æœŸåŠ é€Ÿ2.5å€+ï¼Œå®é™…{speedup:.1f}å€"
    
    print(f"ä¸²è¡Œ: {serial_time:.2f}s, å¹¶è¡Œ: {parallel_time:.2f}s, åŠ é€Ÿ: {speedup:.1f}x")
```

---

## 2. å·¥å…·ç›‘æ§ç³»ç»Ÿ

### å®Œæ•´å®ç°

```python
# app/agent/monitoring/tool_monitoring.py

from collections import defaultdict
from typing import Dict, Any, Optional, List
from datetime import datetime
import time
import statistics

class ToolMonitoring:
    """å·¥å…·ç›‘æ§ç³»ç»Ÿ - ç”Ÿäº§çº§"""
    
    def __init__(self):
        self.tool_stats = defaultdict(lambda: {
            "total_calls": 0,
            "success_calls": 0,
            "failed_calls": 0,
            "latencies_ms": [],
            "error_types": defaultdict(int),
            "last_error": None,
            "first_call_at": None,
            "last_call_at": None
        })
        
        self.enabled = True
    
    async def record_tool_call(
        self,
        tool_name: str,
        args: Dict[str, Any],
        success: bool,
        latency_ms: float,
        error: Optional[Exception] = None,
        result_size: Optional[int] = None
    ):
        """è®°å½•å·¥å…·è°ƒç”¨"""
        if not self.enabled:
            return
        
        stats = self.tool_stats[tool_name]
        now = datetime.now().isoformat()
        
        # åŸºç¡€ç»Ÿè®¡
        stats["total_calls"] += 1
        stats["latencies_ms"].append(latency_ms)
        stats["last_call_at"] = now
        
        if stats["first_call_at"] is None:
            stats["first_call_at"] = now
        
        # æˆåŠŸ/å¤±è´¥
        if success:
            stats["success_calls"] += 1
            if result_size is not None:
                if "result_sizes" not in stats:
                    stats["result_sizes"] = []
                stats["result_sizes"].append(result_size)
        else:
            stats["failed_calls"] += 1
            
            if error:
                error_type = type(error).__name__
                stats["error_types"][error_type] += 1
                stats["last_error"] = {
                    "type": error_type,
                    "message": str(error)[:200],  # é™åˆ¶é•¿åº¦
                    "args": args,
                    "timestamp": now
                }
    
    def get_tool_report(self, tool_name: str) -> Dict[str, Any]:
        """è·å–å•ä¸ªå·¥å…·æŠ¥å‘Š"""
        stats = self.tool_stats[tool_name]
        total = stats["total_calls"]
        
        if total == 0:
            return {"error": "No data"}
        
        latencies = stats["latencies_ms"]
        
        return {
            "tool_name": tool_name,
            "total_calls": total,
            "success_rate": stats["success_calls"] / total,
            "failure_rate": stats["failed_calls"] / total,
            "latency": {
                "min_ms": min(latencies),
                "max_ms": max(latencies),
                "mean_ms": statistics.mean(latencies),
                "median_ms": statistics.median(latencies),
                "p95_ms": self._percentile(latencies, 95),
                "p99_ms": self._percentile(latencies, 99)
            },
            "errors": dict(stats["error_types"]),
            "last_error": stats["last_error"],
            "first_call_at": stats["first_call_at"],
            "last_call_at": stats["last_call_at"]
        }
    
    def get_summary_report(self) -> Dict[str, Any]:
        """è·å–æ±‡æ€»æŠ¥å‘Š"""
        tools_data = []
        
        for tool_name in self.tool_stats.keys():
            tools_data.append(self.get_tool_report(tool_name))
        
        # æ’åº: å¤±è´¥ç‡é™åº
        tools_data.sort(key=lambda x: x.get("failure_rate", 0), reverse=True)
        
        return {
            "total_tools": len(tools_data),
            "tools": tools_data,
            "generated_at": datetime.now().isoformat()
        }
    
    def get_health_alerts(self, thresholds: Dict[str, float] = None) -> List[str]:
        """ç”Ÿæˆå¥åº·å‘Šè­¦"""
        if thresholds is None:
            thresholds = {
                "success_rate": 0.90,
                "p95_latency_ms": 5000,
                "error_count": 10
            }
        
        alerts = []
        
        for tool_name, stats in self.tool_stats.items():
            total = stats["total_calls"]
            if total == 0:
                continue
            
            success_rate = stats["success_calls"] / total
            
            # å‘Šè­¦1: æˆåŠŸç‡ä½
            if success_rate < thresholds["success_rate"]:
                alerts.append({
                    "level": "error",
                    "tool": tool_name,
                    "message": f"æˆåŠŸç‡ {success_rate:.1%} < {thresholds['success_rate']:.0%}",
                    "metric": "success_rate",
                    "value": success_rate
                })
            
            # å‘Šè­¦2: é«˜å»¶è¿Ÿ
            if stats["latencies_ms"]:
                p95 = self._percentile(stats["latencies_ms"], 95)
                if p95 > thresholds["p95_latency_ms"]:
                    alerts.append({
                        "level": "warning",
                        "tool": tool_name,
                        "message": f"P95å»¶è¿Ÿ {p95:.0f}ms > {thresholds['p95_latency_ms']}ms",
                        "metric": "p95_latency",
                        "value": p95
                    })
            
            # å‘Šè­¦3: é«˜é¢‘é”™è¯¯
            for error_type, count in stats["error_types"].items():
                if count > thresholds["error_count"]:
                    alerts.append({
                        "level": "warning",
                        "tool": tool_name,
                        "message": f"é«˜é¢‘é”™è¯¯ {error_type}: {count}æ¬¡",
                        "metric": "error_frequency",
                        "value": count,
                        "error_type": error_type
                    })
        
        return alerts
    
    @staticmethod
    def _percentile(data: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½"""
        if not data:
            return 0.0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡(ç”¨äºæµ‹è¯•æˆ–å®šæœŸæ¸…ç†)"""
        self.tool_stats.clear()

# å…¨å±€å•ä¾‹
_tool_monitoring_instance = None

def get_tool_monitoring() -> ToolMonitoring:
    global _tool_monitoring_instance
    if _tool_monitoring_instance is None:
        _tool_monitoring_instance = ToolMonitoring()
    return _tool_monitoring_instance

# è£…é¥°å™¨: è‡ªåŠ¨ç›‘æ§å·¥å…·è°ƒç”¨
def monitor_tool(func):
    """å·¥å…·ç›‘æ§è£…é¥°å™¨"""
    @functools.wraps(func)
    async def wrapper(tool_name: str, args: dict, *inner_args, **kwargs):
        monitoring = get_tool_monitoring()
        start_time = time.time()
        
        try:
            result = await func(tool_name, args, *inner_args, **kwargs)
            
            # è®¡ç®—ç»“æœå¤§å°
            result_size = len(str(result)) if result else 0
            
            # è®°å½•æˆåŠŸ
            await monitoring.record_tool_call(
                tool_name=tool_name,
                args=args,
                success=True,
                latency_ms=(time.time() - start_time) * 1000,
                result_size=result_size
            )
            
            return result
        except Exception as e:
            # è®°å½•å¤±è´¥
            await monitoring.record_tool_call(
                tool_name=tool_name,
                args=args,
                success=False,
                latency_ms=(time.time() - start_time) * 1000,
                error=e
            )
            raise
    
    return wrapper

# åœ¨ step_node ä½¿ç”¨
@monitor_tool
async def execute_tool_call(tool_name: str, args: dict, tool_map: dict):
    """æ‰§è¡Œå·¥å…·è°ƒç”¨ (å¸¦ç›‘æ§)"""
    tool = tool_map.get(tool_name)
    if not tool:
        raise ValueError(f"Tool {tool_name} not found")
    
    return await tool.ainvoke(args)
```

### APIæ¥å£

```python
# app/api/monitoring_routes.py

from fastapi import APIRouter
from app.agent.monitoring.tool_monitoring import get_tool_monitoring

router = APIRouter(prefix="/monitoring", tags=["monitoring"])

@router.get("/tools/summary")
async def get_tools_summary():
    """è·å–å·¥å…·ç›‘æ§æ±‡æ€»"""
    monitoring = get_tool_monitoring()
    return monitoring.get_summary_report()

@router.get("/tools/{tool_name}")
async def get_tool_detail(tool_name: str):
    """è·å–å•ä¸ªå·¥å…·è¯¦æƒ…"""
    monitoring = get_tool_monitoring()
    return monitoring.get_tool_report(tool_name)

@router.get("/tools/alerts")
async def get_health_alerts():
    """è·å–å¥åº·å‘Šè­¦"""
    monitoring = get_tool_monitoring()
    alerts = monitoring.get_health_alerts()
    
    return {
        "alerts_count": len(alerts),
        "alerts": alerts,
        "generated_at": datetime.now().isoformat()
    }
```

---

## 3. Embeddingç¼“å­˜

### å®Œæ•´å®ç°

```python
# app/agent/services/embedding_cache.py

from functools import lru_cache
import hashlib
import pickle
from typing import List, Optional
import aiofiles
import json

class EmbeddingCache:
    """Embeddingç¼“å­˜æœåŠ¡"""
    
    def __init__(
        self,
        cache_size: int = 1000,
        cache_file: Optional[str] = None
    ):
        self.memory_cache = {}  # {hash: embedding}
        self.cache_size = cache_size
        self.cache_file = cache_file
        
        # ç»Ÿè®¡
        self.hits = 0
        self.misses = 0
        
        # LRUé˜Ÿåˆ—
        self.lru_queue = []
    
    async def initialize(self):
        """å¯åŠ¨æ—¶åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        if self.cache_file and os.path.exists(self.cache_file):
            async with aiofiles.open(self.cache_file, 'rb') as f:
                content = await f.read()
                self.memory_cache = pickle.loads(content)
                print(f"âœ… åŠ è½½Embeddingç¼“å­˜: {len(self.memory_cache)}æ¡")
    
    async def get(self, text: str) -> Optional[List[float]]:
        """è·å–ç¼“å­˜çš„embedding"""
        cache_key = self._generate_key(text)
        
        if cache_key in self.memory_cache:
            self.hits += 1
            
            # æ›´æ–°LRU
            self._touch(cache_key)
            
            return self.memory_cache[cache_key]
        
        self.misses += 1
        return None
    
    async def set(self, text: str, embedding: List[float]):
        """è®¾ç½®ç¼“å­˜"""
        cache_key = self._generate_key(text)
        
        # æ£€æŸ¥å®¹é‡
        if len(self.memory_cache) >= self.cache_size:
            self._evict_lru()
        
        self.memory_cache[cache_key] = embedding
        self.lru_queue.append(cache_key)
    
    async def persist(self):
        """æŒä¹…åŒ–åˆ°æ–‡ä»¶"""
        if not self.cache_file:
            return
        
        async with aiofiles.open(self.cache_file, 'wb') as f:
            await f.write(pickle.dumps(self.memory_cache))
    
    def _generate_key(self, text: str) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        # å½’ä¸€åŒ–æ–‡æœ¬
        normalized = text.strip().lower()
        # MD5 hash
        return hashlib.md5(normalized.encode()).hexdigest()
    
    def _touch(self, key: str):
        """æ›´æ–°LRU"""
        if key in self.lru_queue:
            self.lru_queue.remove(key)
        self.lru_queue.append(key)
    
    def _evict_lru(self):
        """æ·˜æ±°æœ€æ—§çš„"""
        if self.lru_queue:
            old_key = self.lru_queue.pop(0)
            if old_key in self.memory_cache:
                del self.memory_cache[old_key]
    
    @property
    def hit_rate(self) -> float:
        """ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "cache_size": len(self.memory_cache),
            "max_size": self.cache_size,
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": self.hit_rate,
            "memory_usage_mb": len(pickle.dumps(self.memory_cache)) / 1024 / 1024
        }

# å…¨å±€å®ä¾‹
_embedding_cache = EmbeddingCache(
    cache_size=1000,
    cache_file="~/.cache/conversation_agent/embeddings.pkl"
)

async def get_cached_embedding(text: str, embedding_model) -> List[float]:
    """è·å–embedding(å¸¦ç¼“å­˜)"""
    # 1. æŸ¥ç¼“å­˜
    cached = await _embedding_cache.get(text)
    if cached is not None:
        return cached
    
    # 2. è®¡ç®—embedding
    embedding = await embedding_model.aembed_query(text)
    
    # 3. å†™ç¼“å­˜
    await _embedding_cache.set(text, embedding)
    
    return embedding

# åœ¨ context_node ä½¿ç”¨
retrieved_knowledge = await async_load_warehouse_knowledge_cached(
    runtime.store,
    warehouse_code,
    current_message,
    embedding_model,  # ä¼ å…¥model
    limit=5
)

async def async_load_warehouse_knowledge_cached(...):
    # ä½¿ç”¨ç¼“å­˜
    query_embedding = await get_cached_embedding(query_text, embedding_model)
    
    # å‘é‡æ£€ç´¢
    results = await store.asearch(...)
    return results
```

### å®šæœŸæŒä¹…åŒ–

```python
# app/agent/services/cache_persistence.py

import asyncio

async def cache_persistence_worker(interval: int = 300):
    """ç¼“å­˜æŒä¹…åŒ–Worker - æ¯5åˆ†é’Ÿä¿å­˜"""
    while True:
        await asyncio.sleep(interval)
        
        try:
            await _embedding_cache.persist()
            print(f"âœ… Embeddingç¼“å­˜å·²æŒä¹…åŒ–: {_embedding_cache.get_stats()}")
        except Exception as e:
            print(f"âŒ ç¼“å­˜æŒä¹…åŒ–å¤±è´¥: {e}")

# åœ¨åº”ç”¨å¯åŠ¨æ—¶å¯åŠ¨worker
@app.on_event("startup")
async def startup_event():
    # åŠ è½½ç¼“å­˜
    await _embedding_cache.initialize()
    
    # å¯åŠ¨æŒä¹…åŒ–worker
    asyncio.create_task(cache_persistence_worker())

@app.on_event("shutdown")
async def shutdown_event():
    # æœ€ç»ˆæŒä¹…åŒ–
    await _embedding_cache.persist()
```

---

## 4. Traceè¿½è¸ªç³»ç»Ÿ

### å®Œæ•´å®ç°

```python
# app/agent/monitoring/trace_manager.py

import uuid
from contextvars import ContextVar
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime

# Contextå˜é‡ä¼ é€’trace_id
current_trace: ContextVar[Optional['TraceContext']] = ContextVar('trace', default=None)

@dataclass
class NodeTrace:
    """èŠ‚ç‚¹è¿½è¸ª"""
    node_name: str
    started_at: float
    ended_at: Optional[float] = None
    duration_ms: Optional[float] = None
    status: str = "running"
    error: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class TraceContext:
    """è¿½è¸ªä¸Šä¸‹æ–‡"""
    trace_id: str
    user_id: str
    session_id: str
    message: str
    started_at: float
    ended_at: Optional[float] = None
    total_duration_ms: Optional[float] = None
    status: str = "running"
    nodes: List[NodeTrace] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

class TraceManager:
    """è¿½è¸ªç®¡ç†å™¨"""
    
    def __init__(self, max_traces: int = 1000):
        self.traces: Dict[str, TraceContext] = {}
        self.max_traces = max_traces
    
    def start_trace(
        self,
        user_id: str,
        session_id: str,
        message: str
    ) -> str:
        """å¼€å§‹æ–°è¿½è¸ª"""
        trace_id = f"trace_{uuid.uuid4().hex[:12]}"
        
        trace = TraceContext(
            trace_id=trace_id,
            user_id=user_id,
            session_id=session_id,
            message=message,
            started_at=time.time(),
            status="running"
        )
        
        self.traces[trace_id] = trace
        current_trace.set(trace)
        
        # é™åˆ¶å†…å­˜
        if len(self.traces) > self.max_traces:
            self._evict_old_traces()
        
        return trace_id
    
    def log_node_start(self, node_name: str, **metadata):
        """è®°å½•èŠ‚ç‚¹å¼€å§‹"""
        trace = current_trace.get()
        if not trace:
            return
        
        node_trace = NodeTrace(
            node_name=node_name,
            started_at=time.time(),
            status="running",
            metadata=metadata
        )
        
        trace.nodes.append(node_trace)
    
    def log_node_end(
        self,
        node_name: str,
        success: bool = True,
        error: Optional[Exception] = None,
        **metadata
    ):
        """è®°å½•èŠ‚ç‚¹ç»“æŸ"""
        trace = current_trace.get()
        if not trace:
            return
        
        # æ‰¾åˆ°æœ€åä¸€ä¸ªrunningçŠ¶æ€çš„åŒåèŠ‚ç‚¹
        for node_trace in reversed(trace.nodes):
            if node_trace.node_name == node_name and node_trace.status == "running":
                node_trace.ended_at = time.time()
                node_trace.duration_ms = (node_trace.ended_at - node_trace.started_at) * 1000
                node_trace.status = "completed" if success else "failed"
                
                if error:
                    node_trace.error = f"{type(error).__name__}: {str(error)}"
                
                node_trace.metadata.update(metadata)
                break
    
    def end_trace(self, success: bool = True, **metadata):
        """ç»“æŸè¿½è¸ª"""
        trace = current_trace.get()
        if not trace:
            return
        
        trace.ended_at = time.time()
        trace.total_duration_ms = (trace.ended_at - trace.started_at) * 1000
        trace.status = "completed" if success else "failed"
        trace.metadata.update(metadata)
        
        current_trace.set(None)
    
    def get_trace(self, trace_id: str) -> Optional[TraceContext]:
        """è·å–è¿½è¸ªè¯¦æƒ…"""
        return self.traces.get(trace_id)
    
    def _evict_old_traces(self):
        """æ·˜æ±°æ—§è¿½è¸ª"""
        # ä¿ç•™æœ€è¿‘çš„1000æ¡
        if len(self.traces) <= self.max_traces:
            return
        
        sorted_traces = sorted(
            self.traces.items(),
            key=lambda x: x[1].started_at
        )
        
        # åˆ é™¤æœ€æ—§çš„200æ¡
        for trace_id, _ in sorted_traces[:200]:
            del self.traces[trace_id]

# å…¨å±€å®ä¾‹
trace_manager = TraceManager()

# è£…é¥°å™¨: è‡ªåŠ¨è¿½è¸ªèŠ‚ç‚¹
def traced_node(func):
    """èŠ‚ç‚¹è¿½è¸ªè£…é¥°å™¨"""
    @functools.wraps(func)
    async def wrapper(state, *, runtime, **kwargs):
        node_name = func.__name__
        
        trace_manager.log_node_start(node_name)
        
        try:
            result = await func(state, runtime=runtime, **kwargs)
            trace_manager.log_node_end(node_name, success=True)
            return result
        except Exception as e:
            trace_manager.log_node_end(node_name, success=False, error=e)
            raise
    
    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
@traced_node
async def understand_node(state, *, runtime):
    # åŸæœ‰é€»è¾‘
    ...
```

### APIé›†æˆ

```python
# ä¿®æ”¹ chat endpoint
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    # å¼€å§‹è¿½è¸ª
    trace_id = trace_manager.start_trace(
        user_id=request.user_id,
        session_id=request.session_id,
        message=request.message
    )
    
    try:
        result = await agent.ainvoke(...)
        
        # ç»“æŸè¿½è¸ª
        trace_manager.end_trace(success=True)
        
        # è·å–è¿½è¸ªæ•°æ®
        trace = trace_manager.get_trace(trace_id)
        
        return {
            "response": result,
            "trace_id": trace_id,
            "performance": {
                "total_ms": trace.total_duration_ms,
                "nodes": [
                    {
                        "node": n.node_name,
                        "duration_ms": n.duration_ms,
                        "status": n.status
                    }
                    for n in trace.nodes
                ]
            }
        }
    except Exception as e:
        trace_manager.end_trace(success=False)
        raise

# æŸ¥è¯¢è¿½è¸ª
@app.get("/monitoring/trace/{trace_id}")
async def get_trace_detail(trace_id: str):
    trace = trace_manager.get_trace(trace_id)
    if not trace:
        raise HTTPException(404, "Trace not found")
    
    return {
        "trace_id": trace.trace_id,
        "user_id": trace.user_id,
        "message": trace.message,
        "total_duration_ms": trace.total_duration_ms,
        "status": trace.status,
        "nodes": [
            {
                "node": n.node_name,
                "duration_ms": n.duration_ms,
                "status": n.status,
                "error": n.error
            }
            for n in trace.nodes
        ]
    }
```

---

## 5. å·¥å…·æƒé™ç­–ç•¥

### å®Œæ•´å®ç°

```python
# app/agent/core/tool_policy.py

from typing import List, Dict, Literal, Optional
from pydantic import BaseModel

class ToolPolicy(BaseModel):
    """å·¥å…·æƒé™ç­–ç•¥"""
    mode: Literal["allowlist", "denylist"] = "allowlist"
    allow: List[str] = []
    deny: List[str] = []
    
    # å·¥å…·åˆ†ç»„
    groups: Dict[str, List[str]] = {}

class WarehouseToolPolicies(BaseModel):
    """ä»“åº“å·¥å…·ç­–ç•¥é…ç½®"""
    
    # é»˜è®¤ç­–ç•¥
    default: ToolPolicy = ToolPolicy(
        mode="allowlist",
        allow=["*"]  # é»˜è®¤å…è®¸æ‰€æœ‰
    )
    
    # æŒ‰ä»“åº“é…ç½®
    warehouse_policies: Dict[str, ToolPolicy] = {}
    
    # å·¥å…·åˆ†ç»„å®šä¹‰
    tool_groups: Dict[str, List[str]] = {
        "basic": [
            "get_warehouse_info",
            "get_warehouse_stages",
            "query_orders_data_by_date_range"
        ],
        "advanced": [
            "get_stage_current_status",
            "get_warehouse_realtime_overview",
            "detect_stage_anomalies"
        ],
        "admin": [
            "execute_cypher",
            "get_graph_schema"
        ]
    }

class ToolPolicyEnforcer:
    """å·¥å…·ç­–ç•¥æ‰§è¡Œå™¨"""
    
    def __init__(self, policies: WarehouseToolPolicies):
        self.policies = policies
    
    def filter_tools(
        self,
        tools: List[BaseTool],
        warehouse_code: str
    ) -> List[BaseTool]:
        """æ ¹æ®ç­–ç•¥è¿‡æ»¤å·¥å…·"""
        
        # è·å–ä»“åº“ç­–ç•¥
        policy = self.policies.warehouse_policies.get(
            warehouse_code,
            self.policies.default
        )
        
        # æ‰©å±•å·¥å…·ç»„
        expanded_policy = self._expand_groups(policy)
        
        # è¿‡æ»¤
        if expanded_policy.mode == "allowlist":
            if "*" in expanded_policy.allow:
                return tools  # å…è®¸æ‰€æœ‰
            
            return [
                t for t in tools
                if t.name in expanded_policy.allow
            ]
        else:  # denylist
            return [
                t for t in tools
                if t.name not in expanded_policy.deny
            ]
    
    def _expand_groups(self, policy: ToolPolicy) -> ToolPolicy:
        """æ‰©å±•å·¥å…·ç»„ä¸ºå…·ä½“å·¥å…·"""
        expanded_allow = []
        
        for item in policy.allow:
            if item.startswith("@"):  # @basic, @advanced
                group_name = item[1:]
                group_tools = self.policies.tool_groups.get(group_name, [])
                expanded_allow.extend(group_tools)
            else:
                expanded_allow.append(item)
        
        return ToolPolicy(
            mode=policy.mode,
            allow=expanded_allow,
            deny=policy.deny
        )
    
    def check_permission(
        self,
        tool_name: str,
        warehouse_code: str
    ) -> bool:
        """æ£€æŸ¥å·¥å…·æƒé™"""
        policy = self.policies.warehouse_policies.get(
            warehouse_code,
            self.policies.default
        )
        
        expanded = self._expand_groups(policy)
        
        if policy.mode == "allowlist":
            return tool_name in expanded.allow or "*" in policy.allow
        else:
            return tool_name not in expanded.deny

# é…ç½®ç¤ºä¾‹
# config/tool_policies.json
{
  "default": {
    "mode": "allowlist",
    "allow": ["@basic", "@advanced"]
  },
  "warehouse_policies": {
    "20142001": {
      "mode": "allowlist",
      "allow": ["@basic", "@advanced", "@admin"]
    },
    "20142002": {
      "mode": "denylist",
      "deny": ["execute_cypher"]
    }
  },
  "tool_groups": {
    "basic": ["get_warehouse_info", "query_orders_data_by_date_range"],
    "advanced": ["get_stage_current_status", "detect_stage_anomalies"],
    "admin": ["execute_cypher", "get_graph_schema"]
  }
}

# åŠ è½½ç­–ç•¥
def load_tool_policies() -> WarehouseToolPolicies:
    with open("config/tool_policies.json") as f:
        return WarehouseToolPolicies(**json.load(f))

# åœ¨ Agent åˆå§‹åŒ–æ—¶åº”ç”¨
policies = load_tool_policies()
enforcer = ToolPolicyEnforcer(policies)

# åœ¨ context_node è¿‡æ»¤å·¥å…·
filtered_tools = enforcer.filter_tools(
    all_tools,
    warehouse_code=runtime.context.warehouse_code
)

# æ³¨å…¥åˆ°State (ä¾›åç»­èŠ‚ç‚¹ä½¿ç”¨)
state["available_tools"] = [t.name for t in filtered_tools]
```

---

## 6. Skillæ’ä»¶åŒ–

### ç›®æ ‡
- å·¥å…·å®šä¹‰ä¸ä¸šåŠ¡ä»£ç è§£è€¦
- æ”¯æŒçƒ­åŠ è½½æ–°å·¥å…·
- ä¾¿äºå·¥å…·ç‰ˆæœ¬ç®¡ç†

### Skillç›®å½•ç»“æ„

```
skills/
â”œâ”€â”€ warehouse_basic/
â”‚   â”œâ”€â”€ SKILL.md          # æŠ€èƒ½æè¿°
â”‚   â”œâ”€â”€ tools.py          # å·¥å…·å®ç°
â”‚   â””â”€â”€ requirements.txt  # ä¾èµ–
â”œâ”€â”€ hour_analysis/
â”‚   â”œâ”€â”€ SKILL.md
â”‚   â””â”€â”€ tools.py
â””â”€â”€ kg_monitoring/
    â”œâ”€â”€ SKILL.md
    â””â”€â”€ tools.py
```

### SKILL.mdæ ¼å¼

```markdown
# Warehouse Basic Skills

## Description
ä»“åº“åŸºç¡€æŸ¥è¯¢å·¥å…·é›†

## Version
1.0.0

## Author
Warehouse Team

## Tools

### get_warehouse_info
è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯

**Input**:
- warehouse_id (str): ä»“åº“ID

**Output**:
- name (str): ä»“åº“åç§°
- code (str): ä»“åº“ä»£ç 
- location (str): åœ°ç†ä½ç½®

### query_orders_data_by_date_range
æŸ¥è¯¢è®¢å•æ•°æ®

**Input**:
- warehouse_id (str): ä»“åº“ID
- start_date (str): å¼€å§‹æ—¥æœŸ
- end_date (str): ç»“æŸæ—¥æœŸ
- data_type (str): æ•°æ®ç±»å‹ [predict, actual, combined]

**Output**:
- data (List[dict]): è®¢å•æ•°æ®åˆ—è¡¨
```

### SkillåŠ è½½å™¨å®ç°

```python
# app/agent/plugins/skill_loader.py

import os
import importlib.util
from pathlib import Path
from typing import List, Dict
from langchain_core.tools import BaseTool

class SkillLoader:
    """SkillåŠ è½½å™¨"""
    
    def __init__(self, skills_dir: str = "skills"):
        self.skills_dir = Path(skills_dir)
        self.loaded_skills = {}
    
    def discover_skills(self) -> List[str]:
        """å‘ç°æ‰€æœ‰Skill"""
        if not self.skills_dir.exists():
            return []
        
        skills = []
        for skill_dir in self.skills_dir.iterdir():
            if skill_dir.is_dir() and (skill_dir / "SKILL.md").exists():
                skills.append(skill_dir.name)
        
        return skills
    
    def load_skill(self, skill_name: str) -> Dict[str, Any]:
        """åŠ è½½å•ä¸ªSkill"""
        skill_dir = self.skills_dir / skill_name
        
        if not skill_dir.exists():
            raise ValueError(f"Skill {skill_name} not found")
        
        # 1. è§£æ SKILL.md
        metadata = self._parse_skill_md(skill_dir / "SKILL.md")
        
        # 2. åŠ è½½ tools.py
        tools = self._load_tools_module(skill_dir / "tools.py")
        
        skill_data = {
            "name": skill_name,
            "metadata": metadata,
            "tools": tools,
            "loaded_at": datetime.now().isoformat()
        }
        
        self.loaded_skills[skill_name] = skill_data
        
        return skill_data
    
    def _parse_skill_md(self, md_path: Path) -> Dict:
        """è§£æSKILL.md"""
        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç®€å•è§£æ (å¯ä»¥ç”¨markdownè§£æåº“)
        metadata = {
            "description": "",
            "version": "1.0.0",
            "tools": []
        }
        
        # æå–æè¿°
        if "## Description" in content:
            desc_section = content.split("## Description")[1].split("##")[0]
            metadata["description"] = desc_section.strip()
        
        # æå–å·¥å…·åˆ—è¡¨
        if "## Tools" in content:
            tools_section = content.split("## Tools")[1]
            # è§£æå·¥å…·å (###æ ‡é¢˜)
            import re
            tool_names = re.findall(r'###\s+(\w+)', tools_section)
            metadata["tools"] = tool_names
        
        return metadata
    
    def _load_tools_module(self, tools_path: Path) -> List[BaseTool]:
        """åŠ¨æ€åŠ è½½tools.py"""
        if not tools_path.exists():
            return []
        
        # åŠ¨æ€å¯¼å…¥æ¨¡å—
        spec = importlib.util.spec_from_file_location(
            f"skill_tools_{tools_path.parent.name}",
            tools_path
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        # æå–æ‰€æœ‰BaseToolå®ä¾‹
        tools = []
        for attr_name in dir(module):
            attr = getattr(module, attr_name)
            if isinstance(attr, BaseTool):
                tools.append(attr)
        
        return tools
    
    def load_all_skills(self) -> List[BaseTool]:
        """åŠ è½½æ‰€æœ‰Skillçš„å·¥å…·"""
        all_tools = []
        
        for skill_name in self.discover_skills():
            try:
                skill = self.load_skill(skill_name)
                all_tools.extend(skill["tools"])
                print(f"âœ… åŠ è½½Skill: {skill_name} ({len(skill['tools'])}ä¸ªå·¥å…·)")
            except Exception as e:
                print(f"âŒ åŠ è½½Skillå¤±è´¥ {skill_name}: {e}")
        
        return all_tools
    
    def reload_skill(self, skill_name: str) -> Dict[str, Any]:
        """é‡æ–°åŠ è½½Skill (çƒ­é‡è½½)"""
        if skill_name in self.loaded_skills:
            del self.loaded_skills[skill_name]
        
        return self.load_skill(skill_name)

# ä½¿ç”¨
skill_loader = SkillLoader(skills_dir="skills")

# Agentåˆå§‹åŒ–æ—¶åŠ è½½
all_tools = skill_loader.load_all_skills()

# çƒ­é‡è½½API
@app.post("/skills/reload/{skill_name}")
async def reload_skill_endpoint(skill_name: str):
    try:
        skill = skill_loader.reload_skill(skill_name)
        return {
            "success": True,
            "skill": skill["name"],
            "tools_count": len(skill["tools"])
        }
    except Exception as e:
        raise HTTPException(500, str(e))
```

---

## 7. é…ç½®çƒ­é‡è½½

### ç›®æ ‡
- è¿è¡Œæ—¶æ›´æ–°é…ç½®ï¼Œæ— éœ€é‡å¯æœåŠ¡
- æ”¯æŒå·¥å…·ç­–ç•¥ã€æ¨¡å‹å‚æ•°ã€è®°å¿†ç­–ç•¥ç­‰é…ç½®

### å®ç°

```python
# app/agent/core/config_manager.py

import json
import asyncio
from pathlib import Path
from typing import Dict, Any, Callable
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ - æ”¯æŒçƒ­é‡è½½"""
    
    def __init__(self, config_path: str = "config/agent_config.json"):
        self.config_path = Path(config_path)
        self.config: Dict[str, Any] = {}
        self.reload_callbacks: List[Callable] = []
        self.observer = None
    
    async def initialize(self):
        """åˆå§‹åŒ–é…ç½®"""
        await self.load_config()
        self._start_file_watcher()
    
    async def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not self.config_path.exists():
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
            self.config = self._get_default_config()
            return
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {self.config_path}")
    
    async def reload_config(self):
        """é‡æ–°åŠ è½½é…ç½®"""
        old_config = self.config.copy()
        await self.load_config()
        
        # æ£€æµ‹å˜åŒ–
        changes = self._detect_changes(old_config, self.config)
        
        if changes:
            print(f"ğŸ”„ é…ç½®å·²æ›´æ–°: {len(changes)}é¡¹å˜åŒ–")
            
            # è§¦å‘å›è°ƒ
            for callback in self.reload_callbacks:
                try:
                    await callback(self.config, changes)
                except Exception as e:
                    print(f"âŒ é…ç½®å›è°ƒå¤±è´¥: {e}")
    
    def _detect_changes(self, old: dict, new: dict) -> List[str]:
        """æ£€æµ‹é…ç½®å˜åŒ–"""
        changes = []
        
        # æ£€æŸ¥æ‰€æœ‰é”®
        all_keys = set(old.keys()) | set(new.keys())
        
        for key in all_keys:
            if old.get(key) != new.get(key):
                changes.append(key)
        
        return changes
    
    def _start_file_watcher(self):
        """å¯åŠ¨æ–‡ä»¶ç›‘å¬"""
        class ConfigFileHandler(FileSystemEventHandler):
            def __init__(self, manager):
                self.manager = manager
            
            def on_modified(self, event):
                if event.src_path == str(self.manager.config_path):
                    print(f"ğŸ“ æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜åŒ–: {event.src_path}")
                    # å¼‚æ­¥é‡è½½
                    asyncio.create_task(self.manager.reload_config())
        
        event_handler = ConfigFileHandler(self)
        self.observer = Observer()
        self.observer.schedule(
            event_handler,
            str(self.config_path.parent),
            recursive=False
        )
        self.observer.start()
    
    def register_reload_callback(self, callback: Callable):
        """æ³¨å†Œé‡è½½å›è°ƒ"""
        self.reload_callbacks.append(callback)
    
    def get(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®å€¼"""
        keys = key.split('.')
        value = self.config
        
        for k in keys:
            if isinstance(value, dict):
                value = value.get(k)
            else:
                return default
        
        return value if value is not None else default
    
    def _get_default_config(self) -> dict:
        """é»˜è®¤é…ç½®"""
        return {
            "model": {
                "analysis": "qwen_analysis",
                "fast": "qwen_fast",
                "temperature": 0.0
            },
            "tool_policy": {
                "default": {
                    "mode": "allowlist",
                    "allow": ["*"]
                }
            },
            "memory": {
                "load_strategy": "standard",
                "max_entries": 100
            }
        }

# å…¨å±€å®ä¾‹
config_manager = ConfigManager()

# åº”ç”¨å¯åŠ¨
@app.on_event("startup")
async def startup():
    await config_manager.initialize()
    
    # æ³¨å†Œé‡è½½å›è°ƒ
    config_manager.register_reload_callback(on_config_reload)

async def on_config_reload(new_config: dict, changes: List[str]):
    """é…ç½®é‡è½½å›è°ƒ"""
    print(f"ğŸ”„ é…ç½®å·²æ›´æ–°ï¼Œå˜åŒ–é¡¹: {changes}")
    
    # æ ¹æ®å˜åŒ–é¡¹æ›´æ–°è¿è¡Œæ—¶
    if "tool_policy" in changes:
        # é‡æ–°åŠ è½½å·¥å…·ç­–ç•¥
        await reload_tool_policies(new_config["tool_policy"])
    
    if "model" in changes:
        # é‡æ–°ç¼–è¯‘Agent graph
        await agent.recompile_with_new_config(new_config)

# APIæ¥å£
@app.get("/config")
async def get_config():
    return config_manager.config

@app.post("/config/reload")
async def reload_config():
    await config_manager.reload_config()
    return {"success": True, "message": "é…ç½®å·²é‡è½½"}
```

---

## 8. å®æ–½æ£€æŸ¥æ¸…å•

### Week 1: æ€§èƒ½ä¼˜åŒ–

- [ ] **Day 1-2**: å·¥å…·å¹¶è¡ŒåŒ–
  - [ ] ä¿®æ”¹step_nodeæ”¯æŒå¹¶è¡Œ
  - [ ] ç¼–å†™å•å…ƒæµ‹è¯•
  - [ ] æ€§èƒ½å¯¹æ¯”æµ‹è¯•

- [ ] **Day 3-4**: Embeddingç¼“å­˜
  - [ ] å®ç°ç¼“å­˜ç±»
  - [ ] é›†æˆåˆ°context_node
  - [ ] ç›‘æ§å‘½ä¸­ç‡

- [ ] **Day 5**: å·¥å…·ç»“æœç¼“å­˜
  - [ ] å®ç°TTLç¼“å­˜
  - [ ] é›†æˆåˆ°æ‰§è¡Œé€»è¾‘
  - [ ] æµ‹è¯•éªŒè¯

### Week 2: ç›‘æ§ç³»ç»Ÿ

- [ ] **Day 1-2**: å·¥å…·ç›‘æ§
  - [ ] å®ç°ToolMonitoringç±»
  - [ ] é›†æˆåˆ°æ‰€æœ‰å·¥å…·è°ƒç”¨ç‚¹
  - [ ] æ·»åŠ ç›‘æ§API

- [ ] **Day 3-4**: Traceè¿½è¸ª
  - [ ] å®ç°TraceManager
  - [ ] æ·»åŠ èŠ‚ç‚¹è£…é¥°å™¨
  - [ ] é›†æˆåˆ°APIå±‚

- [ ] **Day 5**: Dashboard
  - [ ] å®ç°ç›‘æ§API
  - [ ] ç®€å•HTMLå¯è§†åŒ–
  - [ ] å‘Šè­¦è§„åˆ™é…ç½®

### Week 3-4: æ’ä»¶åŒ–

- [ ] **Week 3**: Skillæ¡†æ¶
  - [ ] Skillç›®å½•ç»“æ„è®¾è®¡
  - [ ] SkillLoaderå®ç°
  - [ ] SKILL.mdè§£æ

- [ ] **Week 4**: å·¥å…·ç­–ç•¥
  - [ ] ToolPolicyå®šä¹‰
  - [ ] ToolPolicyEnforcerå®ç°
  - [ ] é…ç½®æ–‡ä»¶è®¾è®¡

---

## 9. æ€§èƒ½å¯¹æ¯”æµ‹è¯•

### æµ‹è¯•è„šæœ¬

```python
# tests/performance_benchmark.py

import asyncio
import time
from typing import List

class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    async def benchmark_complex_path(
        self,
        agent,
        test_cases: List[str],
        iterations: int = 10
    ):
        """æµ‹è¯•Complexè·¯å¾„æ€§èƒ½"""
        
        results = {
            "before_optimization": [],
            "after_optimization": []
        }
        
        for test_message in test_cases:
            print(f"\næµ‹è¯•: {test_message}")
            
            # ä¼˜åŒ–å‰
            times_before = []
            for _ in range(iterations):
                start = time.time()
                await agent.ainvoke({"messages": [...]})
                times_before.append(time.time() - start)
            
            # ä¼˜åŒ–å (å¯ç”¨å¹¶è¡Œ)
            agent.enable_parallel_execution()
            times_after = []
            for _ in range(iterations):
                start = time.time()
                await agent.ainvoke({"messages": [...]})
                times_after.append(time.time() - start)
            
            # ç»Ÿè®¡
            results["before_optimization"].append({
                "message": test_message,
                "mean_s": statistics.mean(times_before),
                "median_s": statistics.median(times_before),
                "min_s": min(times_before),
                "max_s": max(times_before)
            })
            
            results["after_optimization"].append({
                "message": test_message,
                "mean_s": statistics.mean(times_after),
                "median_s": statistics.median(times_after),
                "speedup": statistics.mean(times_before) / statistics.mean(times_after)
            })
        
        return results
    
    def generate_report(self, results: dict):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("æ€§èƒ½ä¼˜åŒ–å¯¹æ¯”æŠ¥å‘Š")
        print("="*80)
        
        for i, before in enumerate(results["before_optimization"]):
            after = results["after_optimization"][i]
            
            print(f"\næµ‹è¯• {i+1}: {before['message']}")
            print(f"  ä¼˜åŒ–å‰: {before['mean_s']:.2f}s (ä¸­ä½æ•°: {before['median_s']:.2f}s)")
            print(f"  ä¼˜åŒ–å: {after['mean_s']:.2f}s (ä¸­ä½æ•°: {after['median_s']:.2f}s)")
            print(f"  åŠ é€Ÿæ¯”: {after['speedup']:.2f}x")
        
        # æ€»ä½“ç»Ÿè®¡
        avg_speedup = statistics.mean([
            r["speedup"] for r in results["after_optimization"]
        ])
        
        print(f"\nå¹³å‡åŠ é€Ÿ: {avg_speedup:.2f}x")
        print("="*80)

# è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    benchmark = PerformanceBenchmark()
    
    test_cases = [
        "å¯¹æ¯”æœ¬å‘¨å’Œä¸Šå‘¨å…¥åº“è¶‹åŠ¿ï¼Œåˆ†æåŸå› ",
        "åˆ†ææ­å·ä»“æ‰€æœ‰ç¯èŠ‚çš„ä¾èµ–å…³ç³»",
        "å¯¹æ¯”åˆ†æ‹£å’Œä¸Šæ¶ç¯èŠ‚çš„æ•ˆç‡ï¼Œç»™å‡ºä¼˜åŒ–å»ºè®®"
    ]
    
    results = asyncio.run(benchmark.benchmark_complex_path(
        agent, test_cases, iterations=10
    ))
    
    benchmark.generate_report(results)
```

---

## 10. ç›‘æ§Dashboard

### ç®€å•HTMLå®ç°

```python
# app/api/monitoring_dashboard.py

from fastapi import APIRouter
from fastapi.responses import HTMLResponse

router = APIRouter(prefix="/dashboard", tags=["dashboard"])

@router.get("/", response_class=HTMLResponse)
async def monitoring_dashboard():
    """ç›‘æ§Dashboard"""
    
    # è·å–ç›‘æ§æ•°æ®
    tool_monitoring = get_tool_monitoring()
    trace_manager = get_trace_manager()
    
    summary = tool_monitoring.get_summary_report()
    alerts = tool_monitoring.get_health_alerts()
    
    # ç”ŸæˆHTML
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Conversation Agent Monitoring</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            .alert {{ padding: 10px; margin: 10px 0; border-radius: 5px; }}
            .alert.error {{ background: #ffebee; border-left: 4px solid #f44336; }}
            .alert.warning {{ background: #fff3e0; border-left: 4px solid #ff9800; }}
            table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
            th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
            th {{ background: #2196f3; color: white; }}
            tr:nth-child(even) {{ background: #f2f2f2; }}
            .success {{ color: #4caf50; }}
            .failed {{ color: #f44336; }}
        </style>
    </head>
    <body>
        <h1>ğŸ” Conversation Agent ç›‘æ§é¢æ¿</h1>
        
        <div>
            <h2>âš ï¸ å¥åº·å‘Šè­¦ ({len(alerts)})</h2>
            {''.join(f'<div class="alert {a["level"]}">{a["message"]}</div>' for a in alerts)}
        </div>
        
        <div>
            <h2>ğŸ“Š å·¥å…·ç»Ÿè®¡</h2>
            <table>
                <tr>
                    <th>å·¥å…·å</th>
                    <th>è°ƒç”¨æ¬¡æ•°</th>
                    <th>æˆåŠŸç‡</th>
                    <th>P50å»¶è¿Ÿ</th>
                    <th>P95å»¶è¿Ÿ</th>
                    <th>Topé”™è¯¯</th>
                </tr>
                {''.join(self._render_tool_row(tool) for tool in summary["tools"])}
            </table>
        </div>
        
        <div>
            <h2>ğŸ• æœ€è¿‘è¿½è¸ª</h2>
            <!-- è¿½è¸ªåˆ—è¡¨ -->
        </div>
        
        <script>
            // æ¯30ç§’è‡ªåŠ¨åˆ·æ–°
            setTimeout(() => location.reload(), 30000);
        </script>
    </body>
    </html>
    """
    
    return html

def _render_tool_row(self, tool: dict) -> str:
    success_class = "success" if tool["success_rate"] > 0.9 else "failed"
    
    errors = ", ".join([
        f"{err[0]}({err[1]})"
        for err in tool.get("errors", {}).items()
    ][:3])
    
    return f"""
    <tr>
        <td>{tool["tool_name"]}</td>
        <td>{tool["total_calls"]}</td>
        <td class="{success_class}">{tool["success_rate"]:.1%}</td>
        <td>{tool["latency"]["median_ms"]:.0f}ms</td>
        <td>{tool["latency"]["p95_ms"]:.0f}ms</td>
        <td>{errors or "-"}</td>
    </tr>
    """
```

---

## æ€»ç»“

è¿™ä»½å®æ–½æŒ‡å—æä¾›äº†:

1. âœ… 8ä¸ªä¼˜åŒ–é¡¹çš„å®Œæ•´ä»£ç 
2. âœ… å®æ–½æ£€æŸ¥æ¸…å•
3. âœ… æ€§èƒ½æµ‹è¯•è„šæœ¬
4. âœ… ç›‘æ§Dashboard

**å»ºè®®å®æ–½é¡ºåº**:

```
Week 1: æ€§èƒ½ä¼˜åŒ– (ç«‹å³è§æ•ˆ)
  â†’ å·¥å…·å¹¶è¡ŒåŒ– + ç¼“å­˜

Week 2: ç›‘æ§ç³»ç»Ÿ (æå‡å¯è§‚æµ‹æ€§)
  â†’ å·¥å…·ç›‘æ§ + Traceè¿½è¸ª

Week 3-4: æ’ä»¶åŒ– (æå‡æ‰©å±•æ€§)
  â†’ Skillæ¡†æ¶ + é…ç½®çƒ­é‡è½½

åç»­: æ ¹æ®ä¸šåŠ¡éœ€æ±‚å†³å®šæ˜¯å¦éœ€è¦Gateway
```

æ‰€æœ‰ä»£ç éƒ½å¯ä»¥ç›´æ¥é›†æˆåˆ°æ‚¨çš„ç°æœ‰é¡¹ç›®ï¼
