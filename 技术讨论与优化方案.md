# æŠ€æœ¯è®¨è®ºï¼šConversation Agent æ¶æ„ä¼˜åŒ–æ–¹æ¡ˆ

> **åŸºäº**: Moltbotæ¶æ„åˆ†æ  
> **é’ˆå¯¹**: myagent.MD ç¬¬åäºŒç« æå‡ºçš„è®¨è®ºè¦ç‚¹

---

## ç›®å½•

1. [æ¶æ„å±‚é¢è®¨è®º](#æ¶æ„å±‚é¢è®¨è®º)
2. [æ€§èƒ½å±‚é¢è®¨è®º](#æ€§èƒ½å±‚é¢è®¨è®º)
3. [è®°å¿†ç³»ç»Ÿè®¨è®º](#è®°å¿†ç³»ç»Ÿè®¨è®º)
4. [å¯è§‚æµ‹æ€§è®¨è®º](#å¯è§‚æµ‹æ€§è®¨è®º)
5. [Moltbotå€Ÿé‰´æ–¹æ¡ˆ](#moltbotå€Ÿé‰´æ–¹æ¡ˆ)

---

## æ¶æ„å±‚é¢è®¨è®º

### è®¨è®ºç‚¹1: åŒè·¯å¾„è®¾è®¡çš„è¾¹ç•Œåˆ¤æ–­

**æ‚¨çš„é—®é¢˜**:
> å½“å‰åŸºäºå…³é”®è¯è§„åˆ™ + LLM åˆ¤æ–­ï¼Œæ˜¯å¦å¯ä»¥å¼•å…¥æ›´ç²¾å‡†çš„åˆ†ç±»æ¨¡å‹ï¼Ÿ

#### å½“å‰æ–¹æ¡ˆåˆ†æ

```python
# æ‚¨çš„å®ç° (æ··åˆç­–ç•¥)
def quick_complexity_check(message: str) -> Optional[str]:
    COMPLEX_KEYWORDS = ["å¯¹æ¯”", "æ¯”è¾ƒ", "åˆ†æ", "è¶‹åŠ¿", ...]
    
    # è§„åˆ™1: çŸ­æ¶ˆæ¯ + æ— å…³é”®è¯ = standard
    if len(message) < 30 and not any(kw in message for kw in COMPLEX_KEYWORDS):
        return "standard"
    
    # è§„åˆ™2: 2+ å…³é”®è¯ = complex
    if sum(1 for kw in COMPLEX_KEYWORDS if kw in message) >= 2:
        return "complex"
    
    # æ— æ³•ç¡®å®š â†’ LLM
    return None
```

**ä¼˜ç‚¹**:
- âœ… 80%æƒ…å†µå¿«é€Ÿåˆ¤æ–­(O(n)å…³é”®è¯åŒ¹é…)
- âœ… é™ä½LLMè°ƒç”¨æˆæœ¬
- âœ… è§„åˆ™å¯è§£é‡Šæ€§å¼º

**é—®é¢˜**:
- âŒ å…³é”®è¯è¦†ç›–ä¸å®Œæ•´("ä¸ºä»€ä¹ˆæµé€Ÿé™ä½"å¯èƒ½æ¼åˆ¤)
- âŒ æ— æ³•ç†è§£è¯­ä¹‰("å¿«é€ŸæŸ¥ä¸€ä¸‹"vs"æ·±å…¥åˆ†æ")
- âŒ è¯¯åˆ¤å½±å“ç”¨æˆ·ä½“éªŒ

#### Moltbotæ–¹æ¡ˆ

```typescript
// Moltbotæ²¡æœ‰Standard/Complexè·¯å¾„åŒºåˆ†
// ä½†æœ‰ç±»ä¼¼çš„å·¥å…·è°ƒç”¨å¤æ‚åº¦åˆ¤æ–­

// Pi Agentçš„ReActå¾ªç¯ (æœ€å¤š50è½®)
agent.run({
    maxIterations: 50,  // ç®€å•é—®é¢˜å¯èƒ½3-5è½®ï¼Œå¤æ‚é—®é¢˜20-30è½®
})
```

**å¯¹æ¯”**:
- Moltbotä¾èµ–Agentè‡ªé€‚åº”è¿­ä»£
- æ‚¨çš„æ–¹æ¡ˆæå‰è§„åˆ’ï¼Œæ›´é«˜æ•ˆ

#### æ”¹è¿›å»ºè®®

**æ–¹æ¡ˆA: è½»é‡çº§BERTåˆ†ç±»å™¨** (æ¨è)

```python
# è®­ç»ƒå°å‹åˆ†ç±»æ¨¡å‹
from transformers import AutoModelForSequenceClassification, AutoTokenizer

class ComplexityClassifier:
    def __init__(self):
        # ä½¿ç”¨ä¸­æ–‡BERTå°æ¨¡å‹ (30MB)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            "hfl/chinese-roberta-wwm-ext-small",
            num_labels=2  # standard / complex
        )
        self.tokenizer = AutoTokenizer.from_pretrained(...)
    
    def predict(self, message: str) -> tuple[str, float]:
        """è¿”å› (complexity, confidence)"""
        inputs = self.tokenizer(message, return_tensors="pt")
        outputs = self.model(**inputs)
        probs = torch.softmax(outputs.logits, dim=-1)
        
        complexity = "complex" if probs[0][1] > 0.6 else "standard"
        confidence = probs[0][1].item() if complexity == "complex" else probs[0][0].item()
        
        return complexity, confidence

# æ··åˆç­–ç•¥å‡çº§
async def hybrid_complexity_check(message):
    # 1. è§„åˆ™å±‚ (æå¿«)
    rule_result = quick_complexity_check(message)
    if rule_result and len(message) < 20:  # çŸ­æ¶ˆæ¯ä¿¡ä»»è§„åˆ™
        return rule_result
    
    # 2. åˆ†ç±»å™¨ (å¿«)
    complexity, confidence = classifier.predict(message)
    if confidence > 0.8:  # é«˜ç½®ä¿¡åº¦ç›´æ¥è¿”å›
        return complexity
    
    # 3. LLM (å‡†ç¡®ä½†æ…¢)
    return await llm_complexity_check(message)
```

**ä¼˜ç‚¹**:
- âœ… 90%+æƒ…å†µç”±åˆ†ç±»å™¨å†³ç­–(æ¨ç†<10ms)
- âœ… è¯­ä¹‰ç†è§£èƒ½åŠ›å¼º
- âœ… å¯æŒç»­è®­ç»ƒä¼˜åŒ–

**æˆæœ¬**:
- éœ€è¦æ ‡æ³¨1000+æ ·æœ¬è®­ç»ƒ
- æ¨¡å‹æ–‡ä»¶30MB
- CPUæ¨ç†å»¶è¿Ÿ<10ms

**è®­ç»ƒæ•°æ®ç¤ºä¾‹**:
```
"ä»Šå¤©å…¥åº“é‡å¤šå°‘ï¼Ÿ" â†’ standard
"å¯¹æ¯”æœ¬å‘¨å’Œä¸Šå‘¨çš„å…¥åº“è¶‹åŠ¿å¹¶åˆ†æåŸå› " â†’ complex
"æ­å·ä»“çŠ¶æ€" â†’ standard
"ä¸ºä»€ä¹ˆåˆ†æ‹£ç¯èŠ‚æ•ˆç‡æŒç»­ä¸‹é™ï¼Ÿ" â†’ complex
```

---

**æ–¹æ¡ˆB: Prompt Engineeringä¼˜åŒ–** (å¿«é€Ÿå®æ–½)

```python
# ä¼˜åŒ–LLMåˆ¤æ–­æç¤ºè¯
COMPLEXITY_PROMPT = """
åˆ¤æ–­ä»»åŠ¡å¤æ‚åº¦çš„æ ‡å‡†ï¼š

**Standard (ç®€å•)**:
- å•ä¸€äº‹å®æŸ¥è¯¢: "ä»Šå¤©å…¥åº“å¤šå°‘"
- ç®€å•çŠ¶æ€æŸ¥è¯¢: "æ­å·ä»“çŠ¶æ€"
- å•ä¸ªæŒ‡æ ‡æŸ¥è¯¢: "åˆ†æ‹£ç¯èŠ‚é€Ÿåº¦"

**Complex (å¤æ‚)**:
- å¤šç»´å¯¹æ¯”: "å¯¹æ¯”Aå’ŒB"
- è¶‹åŠ¿åˆ†æ: "åˆ†æXè¶‹åŠ¿"
- æ ¹å› åˆ†æ: "ä¸ºä»€ä¹ˆXå‘ç”Ÿ"
- ä¼˜åŒ–å»ºè®®: "å¦‚ä½•æ”¹è¿›X"
- å¤šæ­¥éª¤æ¨ç†: éœ€è¦3+æ­¥éª¤æ‰èƒ½å›ç­”

âš ï¸ é™·é˜±ï¼š
- "å¿«é€Ÿçœ‹ä¸€ä¸‹Xæ•°æ®" â†’ standard (è™½æœ‰"çœ‹ä¸€ä¸‹"ä½†æœ¬è´¨æ˜¯æŸ¥è¯¢)
- "å¸®æˆ‘åˆ†æä¸€ä¸‹" â†’ çœ‹å…·ä½“å†…å®¹ï¼Œä¸èƒ½ä»…å‡­"åˆ†æ"åˆ¤æ–­

å½“å‰é—®é¢˜: {message}
å¤æ‚åº¦: 
"""
```

**é¢„æœŸæ•ˆæœ**:
- è¯¯åˆ¤ç‡é™ä½åˆ°5%ä»¥ä¸‹
- LLMåˆ¤æ–­å‡†ç¡®ç‡95%+

---

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **çŸ­æœŸ** (1-2å‘¨): æ–¹æ¡ˆB (Promptä¼˜åŒ–)
   - æˆæœ¬ä½ï¼Œç«‹å³è§æ•ˆ
   - æ”¶é›†è¯¯åˆ¤æ ·æœ¬

2. **ä¸­æœŸ** (1-2æœˆ): æ–¹æ¡ˆA (åˆ†ç±»å™¨)
   - ç§¯ç´¯æ ‡æ³¨æ•°æ®
   - è®­ç»ƒè½»é‡æ¨¡å‹
   - æ›¿ä»£80% LLMè°ƒç”¨

3. **ç›‘æ§æŒ‡æ ‡**:
   ```python
   stats = {
       "complexity_decisions": {
           "rule_matched": 0,      # è§„åˆ™å±‚
           "classifier_high_conf": 0,  # åˆ†ç±»å™¨é«˜ç½®ä¿¡
           "llm_fallback": 0,      # LLMå…œåº•
       },
       "misclassifications": 0,   # ç”¨æˆ·åé¦ˆçš„è¯¯åˆ¤
   }
   ```

---

### è®¨è®ºç‚¹2: è®°å¿†è·¯ç”±å™¨çš„è§¦å‘è¯è¦†ç›–

**æ‚¨çš„é—®é¢˜**:
> `FULL_STRATEGY_KEYWORDS` æ˜¯å¦è¦†ç›–å®Œæ•´ï¼Ÿå¦‚ä½•å¹³è¡¡åŠ è½½å¼€é”€ä¸ä¸Šä¸‹æ–‡å®Œæ•´æ€§ï¼Ÿ

#### å½“å‰è§¦å‘è¯

```python
FULL_STRATEGY_KEYWORDS = [
    # å†å²ç›¸å…³
    "ä¹‹å‰", "ä¸Šæ¬¡", "å†å²", "ä»¥å‰", "è¿‡å»",
    # è¶‹åŠ¿ç›¸å…³
    "è¶‹åŠ¿", "å˜åŒ–", "å¯¹æ¯”", "æ¯”è¾ƒ", "åŒæ¯”", "ç¯æ¯”",
    # å›é¡¾ç›¸å…³
    "å›é¡¾", "æ€»ç»“", "å¤ç›˜",
]
```

#### é—æ¼åœºæ™¯åˆ†æ

| ç”¨æˆ·è¡¨è¿° | æ˜¯å¦è§¦å‘FULL | åº”è¯¥è§¦å‘? | å»ºè®®è¡¥å…… |
|---------|-------------|----------|---------|
| "ä¸Šå‘¨æˆ‘ä»¬è®¨è®ºè¿‡çš„é‚£ä¸ªé—®é¢˜" | âœ… ("ä¸Šå‘¨") | âœ… | - |
| "è¿˜è®°å¾—å—ï¼Œä¸Šä¸ªæœˆ..." | âŒ | âœ… | "è¿˜è®°å¾—", "è®°å¾—" |
| "è·Ÿä¸Šæ¬¡ä¸€æ ·çš„æƒ…å†µ" | âœ… ("ä¸Šæ¬¡") | âœ… | - |
| "æŒç»­çš„æ€§èƒ½ä¸‹é™" | âŒ | âœ… | "æŒç»­", "ä¸€ç›´" |
| "æœ€è¿‘å‡ å¤©çš„æ•°æ®" | âŒ | ğŸ¤” å¯é€‰ | - |
| "è¿™ä¸ªæœˆè¡¨ç°å¦‚ä½•" | âŒ | ğŸ¤” å¯é€‰ | - |

#### Moltbotçš„ä¼šè¯ç®¡ç†ç­–ç•¥

```typescript
// Moltbotæ²¡æœ‰æ˜¾å¼çš„è®°å¿†è·¯ç”±
// ä½†æœ‰ä¼šè¯å‹ç¼©æœºåˆ¶

class SessionManager {
    async pruneSession(session: Session): Promise<Session> {
        const maxMessages = 100;
        const maxTokens = 100000;
        
        // 1. æ¶ˆæ¯æ•°é‡é™åˆ¶
        if (session.messages.length > maxMessages) {
            session.messages = session.messages.slice(-maxMessages);
        }
        
        // 2. Tokené™åˆ¶ - æ‘˜è¦å‹ç¼©
        if (totalTokens > maxTokens) {
            await this.compactSession(session);
        }
        
        return session;
    }
    
    async compactSession(session: Session): Promise<void> {
        // å‰åŠéƒ¨åˆ†ç”Ÿæˆæ‘˜è¦
        const oldMessages = session.messages.slice(0, length / 2);
        const summary = await this.generateSummary(oldMessages);
        
        // æ›¿æ¢ä¸ºæ‘˜è¦æ¶ˆæ¯
        session.messages = [
            { role: 'system', content: `Previous summary:\n${summary}` },
            ...session.messages.slice(length / 2)
        ];
    }
}
```

**å¯¹æ¯”**:
- Moltbot: å§‹ç»ˆåŠ è½½å®Œæ•´ä¼šè¯ï¼Œè‡ªåŠ¨å‹ç¼©
- æ‚¨çš„æ–¹æ¡ˆ: æŒ‰éœ€åŠ è½½ï¼Œæ›´ç²¾ç»†

#### æ”¹è¿›å»ºè®®

**æ–¹æ¡ˆA: æ‰©å……è§¦å‘è¯åº“**

```python
FULL_STRATEGY_KEYWORDS = [
    # === æ—¶é—´å›æº¯ ===
    "ä¹‹å‰", "ä¸Šæ¬¡", "å†å²", "ä»¥å‰", "è¿‡å»",
    "ä¸Šå‘¨", "ä¸Šä¸ªæœˆ", "ä¸Šå­£åº¦", "å»å¹´",
    "æœ€è¿‘", "è¿‘æœŸ", "è¿™æ®µæ—¶é—´",  # æ–°å¢
    
    # === è®°å¿†å¬å› ===
    "è¿˜è®°å¾—", "è®°å¾—", "æåˆ°è¿‡", "è¯´è¿‡",  # æ–°å¢
    "é‚£æ¬¡", "é‚£ä¸ª", "å½“æ—¶",  # æ–°å¢
    
    # === è¶‹åŠ¿åˆ†æ ===
    "è¶‹åŠ¿", "å˜åŒ–", "å¯¹æ¯”", "æ¯”è¾ƒ", "åŒæ¯”", "ç¯æ¯”",
    "æŒç»­", "ä¸€ç›´", "è¿ç»­", "æ³¢åŠ¨",  # æ–°å¢
    
    # === å›é¡¾æ€»ç»“ ===
    "å›é¡¾", "æ€»ç»“", "å¤ç›˜",
]
```

**æ–¹æ¡ˆB: æ™ºèƒ½åŠ è½½ç­–ç•¥** (æ¨è)

```python
class AdaptiveMemoryRouter:
    """è‡ªé€‚åº”è®°å¿†è·¯ç”±å™¨"""
    
    @staticmethod
    async def determine_strategy(
        message: str,
        current_session_length: int,
        last_load_time: Optional[datetime]
    ) -> MemoryLoadStrategy:
        # è§„åˆ™1: æ˜ç¡®çš„å†å²å…³é”®è¯ â†’ FULL
        if any(kw in message for kw in FULL_STRATEGY_KEYWORDS):
            return MemoryLoadStrategy.FULL
        
        # è§„åˆ™2: ä¼šè¯å†…é—®é¢˜(æŒ‡ä»£è¯) â†’ FULL
        if _has_pronoun_reference(message):  # "å®ƒ"ï¼Œ"è¿™ä¸ª"ï¼Œ"é‚£ä¸ª"
            return MemoryLoadStrategy.FULL
        
        # è§„åˆ™3: é•¿ä¼šè¯ + æ—¶é—´é—´éš”é•¿ â†’ FULL (é¿å…é—å¿˜)
        if current_session_length > 10 and _time_since(last_load_time) > 3600:
            return MemoryLoadStrategy.FULL
        
        # é»˜è®¤: STANDARD
        return MemoryLoadStrategy.STANDARD
    
    @staticmethod
    def _has_pronoun_reference(message: str) -> bool:
        """æ£€æµ‹æŒ‡ä»£è¯"""
        pronouns = ["å®ƒ", "è¿™ä¸ª", "é‚£ä¸ª", "è¿™äº›", "é‚£äº›", "åˆšæ‰", "åˆšåˆš"]
        return any(p in message for p in pronouns)
```

**æ–¹æ¡ˆC: åˆ†å±‚åŠ è½½** (å¹³è¡¡æ€§èƒ½)

```python
class TieredMemoryLoader:
    """åˆ†å±‚è®°å¿†åŠ è½½"""
    
    TIERS = {
        "minimal": ["profile"],                    # ä»…ç”»åƒ
        "standard": ["profile", "activity"],       # å½“å‰ç­–ç•¥
        "extended": ["profile", "activity", "recent_history"],  # æ–°å¢
        "full": ["profile", "activity", "history"]
    }
    
    async def load(self, user_id: str, tier: str):
        components = self.TIERS[tier]
        
        memory = {}
        if "profile" in components:
            memory["profile"] = await self.load_profile(user_id)
        
        if "activity" in components:
            memory["activity"] = await self.load_activity(user_id, limit=20)
        
        if "recent_history" in components:
            # åªåŠ è½½æœ€è¿‘3æ¡å†å²(æ€§èƒ½ä¼˜åŒ–)
            memory["history"] = await self.load_history(user_id, limit=3)
        
        if "history" in components:
            # å®Œæ•´å†å²
            memory["history"] = await self.load_history(user_id)
        
        return memory
```

**è§¦å‘ç­–ç•¥**:
```python
def determine_tier(message: str, session_context: dict) -> str:
    # minimal: ç®€å•é—®å€™
    if message in ["ä½ å¥½", "åœ¨å—", "hi"]:
        return "minimal"
    
    # extended: æœ‰å†å²æš—ç¤ºä½†ä¸å¼ºçƒˆ
    if any(kw in message for kw in ["æœ€è¿‘", "è¿‘æœŸ", "è¿™æ®µæ—¶é—´"]):
        return "extended"
    
    # full: æ˜ç¡®å†å²/è¶‹åŠ¿
    if any(kw in message for kw in FULL_STRATEGY_KEYWORDS):
        return "full"
    
    # standard: é»˜è®¤
    return "standard"
```

**æ€§èƒ½å¯¹æ¯”**:
| ç­–ç•¥ | åŠ è½½å†…å®¹ | é¢„è®¡å»¶è¿Ÿ | é€‚ç”¨æ¯”ä¾‹ |
|------|---------|---------|---------|
| minimal | profile | 5-10ms | 5% |
| standard | profile + activity | 20-30ms | 70% |
| extended | + recent_history(3æ¡) | 50-80ms | 15% |
| full | + history(å®Œæ•´) | 100-200ms | 10% |

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **çŸ­æœŸ**: æ–¹æ¡ˆB (è‡ªé€‚åº”è·¯ç”±) + æ‰©å……è§¦å‘è¯
   - å¢åŠ æŒ‡ä»£è¯æ£€æµ‹
   - å¢åŠ ä¼šè¯çŠ¶æ€æ„ŸçŸ¥

2. **ä¸­æœŸ**: æ–¹æ¡ˆC (åˆ†å±‚åŠ è½½)
   - å¼•å…¥extendedå±‚
   - é™ä½å¹³å‡å»¶è¿Ÿ

3. **ç›‘æ§æŒ‡æ ‡**:
   ```python
   memory_stats = {
       "strategy_distribution": {
           "minimal": 0,
           "standard": 0,
           "extended": 0,
           "full": 0
       },
       "avg_load_time_ms": {},
       "cache_hit_rate": 0.0
   }
   ```

---

### è®¨è®ºç‚¹3: Complexè·¯å¾„çš„æ­¥éª¤æ•°é™åˆ¶

**æ‚¨çš„é—®é¢˜**:
> å½“å‰ `max_steps=5`ï¼Œå¯¹äºæå¤æ‚ä»»åŠ¡æ˜¯å¦è¶³å¤Ÿï¼Ÿ

#### å½“å‰é™åˆ¶

```python
class ExecutionPlan(TypedDict):
    max_steps: int  # é»˜è®¤5ï¼Œé˜²æ­»å¾ªç¯
```

#### Moltbotçš„åšæ³•

```typescript
// Pi Agenté…ç½®
const agent = createPiAgent({
    maxIterations: 50,  // å…¨å±€æœ€å¤§è¿­ä»£
    timeout: 300000,    // 5åˆ†é’Ÿè¶…æ—¶
});
```

**å¯¹æ¯”**:
- Moltbot: å…¨å±€50è½®ï¼Œä¾èµ–è¶…æ—¶ä¿æŠ¤
- æ‚¨çš„æ–¹æ¡ˆ: 5æ­¥ç¡¬é™åˆ¶ï¼Œæ›´ä¿å®ˆ

#### ç»Ÿè®¡åˆ†æå»ºè®®

```python
# å»ºè®®æ”¶é›†å®é™…æ­¥éª¤æ•°åˆ†å¸ƒ
step_distribution = {
    "1_step": 0,      # 45%
    "2_steps": 0,     # 30%
    "3_steps": 0,     # 15%
    "4_steps": 0,     # 7%
    "5_steps": 0,     # 2%
    "5+_steps": 0,    # 1% (å½“å‰è¢«æˆªæ–­)
}
```

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: åŠ¨æ€æ­¥éª¤é™åˆ¶** (æ¨è)

```python
def calculate_max_steps(understanding: UnderstandingResult) -> int:
    """æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è®¡ç®—"""
    base_steps = 3
    
    # å› ç´ 1: å­é—®é¢˜æ•°é‡
    sub_questions = len(understanding.get("sub_questions", []))
    steps_from_questions = min(sub_questions, 5)
    
    # å› ç´ 2: æ„å›¾ç±»å‹
    intent_multiplier = {
        "query_data": 1.0,
        "analyze_trend": 1.5,
        "compare": 2.0,
        "optimize": 2.5,
    }
    multiplier = intent_multiplier.get(understanding["intent"], 1.0)
    
    # è®¡ç®—
    max_steps = int((base_steps + steps_from_questions) * multiplier)
    
    # é™åˆ¶èŒƒå›´
    return min(max(max_steps, 3), 10)  # 3-10æ­¥

# ä½¿ç”¨
execution_plan["max_steps"] = calculate_max_steps(understanding)
```

**æ–¹æ¡ˆB: æ­¥éª¤é¢„ç®—åˆ¶**

```python
class StepBudgetManager:
    """æ­¥éª¤é¢„ç®—ç®¡ç†å™¨"""
    
    def __init__(self, total_budget: int = 10):
        self.total = total_budget
        self.used = 0
        self.step_costs = {
            "query": 1,      # æŸ¥è¯¢1åˆ†
            "analyze": 2,    # åˆ†æ2åˆ†
            "compare": 2,    # å¯¹æ¯”2åˆ†
            "synthesize": 1, # ç»¼åˆ1åˆ†
        }
    
    def can_execute(self, step: PlanStep) -> bool:
        cost = self.step_costs.get(step["action"], 1)
        return self.used + cost <= self.total
    
    def consume(self, step: PlanStep):
        cost = self.step_costs.get(step["action"], 1)
        self.used += cost
```

**æ–¹æ¡ˆC: å€Ÿé‰´Moltbotçš„è¶…æ—¶æœºåˆ¶**

```python
# åœ¨ step_node å¢åŠ æ—¶é—´é¢„ç®—
MAX_EXECUTION_TIME = 60  # ç§’

async def step_node_with_timeout(state, *, runtime):
    start_time = time.time()
    
    while True:
        # æ£€æŸ¥æ—¶é—´é¢„ç®—
        if time.time() - start_time > MAX_EXECUTION_TIME:
            return {
                "execution_plan": {
                    ...execution_plan,
                    "status": "timeout",
                    "error": "æ‰§è¡Œè¶…æ—¶ï¼Œå·²å®Œæˆ {n} ä¸ªæ­¥éª¤"
                }
            }
        
        # æ­£å¸¸æ‰§è¡Œ
        ...
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆC (è¶…æ—¶ä¿æŠ¤)
   - æ·»åŠ 60ç§’å…¨å±€è¶…æ—¶
   - é˜²æ­¢ç”¨æˆ·ç­‰å¾…è¿‡ä¹…

2. **1å‘¨å†…**: æ–¹æ¡ˆA (åŠ¨æ€é™åˆ¶)
   - æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´
   - 3-10æ­¥èŒƒå›´

3. **ç›‘æ§**: æ”¶é›†å®é™…æ­¥éª¤åˆ†å¸ƒæ•°æ®
   ```python
   if step_count >= max_steps:
       logger.warning(
           f"Steps truncated: {step_count} >= {max_steps}, "
           f"intent={intent}, sub_questions={len(sub_questions)}"
       )
   ```

---

## æ€§èƒ½å±‚é¢è®¨è®º

### è®¨è®ºç‚¹1: å‘é‡æ£€ç´¢é˜»å¡

**æ‚¨çš„é—®é¢˜**:
> è™½ç„¶ä½¿ç”¨äº†å¼‚æ­¥ç‰ˆæœ¬ï¼Œä½† embedding è®¡ç®—ä»åœ¨ä¸»çº¿ç¨‹ã€‚æ˜¯å¦éœ€è¦å•ç‹¬çš„ embedding workerï¼Ÿ

#### å½“å‰å®ç°

```python
# context_node ä¸­
retrieved_knowledge = await async_load_warehouse_knowledge(
    runtime.store, warehouse_code, current_message, limit=5
)

# å†…éƒ¨å®ç°
async def async_load_warehouse_knowledge(...):
    # embedding è®¡ç®— (é˜»å¡ä¸»çº¿ç¨‹)
    query_embedding = await embedding_model.aembed_query(query_text)
    
    # å‘é‡æ£€ç´¢ (å¼‚æ­¥)
    results = await store.asearch(
        ("warehouse_context", warehouse_code),
        query=query_embedding
    )
```

#### Moltbotçš„åšæ³•

Moltbotæ²¡æœ‰å‘é‡æ£€ç´¢ï¼Œä½†æœ‰ç±»ä¼¼çš„æ²™ç®±æ‰§è¡Œéš”ç¦»ï¼š

```typescript
// æ²™ç®±å·¥å…·æ‰§è¡Œåœ¨ç‹¬ç«‹å®¹å™¨
async function executeTool(tool: string, args: any) {
    if (needsSandbox(tool)) {
        // åœ¨Dockerå®¹å™¨ä¸­æ‰§è¡Œ
        return await docker.exec(tool, args);
    }
    
    // æœ¬åœ°æ‰§è¡Œ
    return await localExec(tool, args);
}
```

#### æ€§èƒ½åˆ†æ

**Embeddingè®¡ç®—è€—æ—¶**:
```
- text-embedding-v4 (1536ç»´)
- çŸ­æ–‡æœ¬(50å­—): ~50-100ms (CPU)
- é•¿æ–‡æœ¬(500å­—): ~200-500ms (CPU)
```

**æ˜¯å¦éœ€è¦Worker?**

| æ–¹æ¡ˆ | å»¶è¿Ÿ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|--------|----------|
| **å½“å‰æ–¹æ¡ˆ** (ä¸»çº¿ç¨‹) | 50-100ms | ä½ | QPS < 100 |
| **Workeræ–¹æ¡ˆ** (è¿›ç¨‹æ± ) | 80-150ms | ä¸­ | QPS > 100 |
| **GPUåŠ é€Ÿ** | 10-20ms | é«˜ | QPS > 500 |

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: é¢„è®¡ç®—ç¼“å­˜** (æ¨è)

```python
class EmbeddingCache:
    """Embeddingç¼“å­˜å±‚"""
    
    def __init__(self):
        self.cache = LRUCache(maxsize=1000)
        self.cache_hits = 0
        self.cache_misses = 0
    
    async def get_embedding(self, text: str) -> List[float]:
        # ç”Ÿæˆcache key
        cache_key = hashlib.md5(text.encode()).hexdigest()
        
        # æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            self.cache_hits += 1
            return self.cache[cache_key]
        
        # è®¡ç®—embedding
        self.cache_misses += 1
        embedding = await embedding_model.aembed_query(text)
        self.cache[cache_key] = embedding
        
        return embedding
    
    @property
    def hit_rate(self) -> float:
        total = self.cache_hits + self.cache_misses
        return self.cache_hits / total if total > 0 else 0.0

# ä½¿ç”¨
cache = EmbeddingCache()
query_embedding = await cache.get_embedding(query_text)
```

**é¢„æœŸæ•ˆæœ**:
- ç¼“å­˜å‘½ä¸­ç‡40-60%
- å¹³å‡å»¶è¿Ÿé™ä½åˆ°30-50ms
- å†…å­˜å¢åŠ ~50MB

**æ–¹æ¡ˆB: åå°Workeræ± ** (é«˜QPSåœºæ™¯)

```python
# ä½¿ç”¨ProcessPoolExecutor
from concurrent.futures import ProcessPoolExecutor

class EmbeddingWorkerPool:
    def __init__(self, num_workers: int = 4):
        self.executor = ProcessPoolExecutor(max_workers=num_workers)
        self.embedding_model = None  # æ¯ä¸ªworkerç‹¬ç«‹åŠ è½½
    
    async def embed_async(self, text: str) -> List[float]:
        loop = asyncio.get_event_loop()
        
        # åœ¨workerè¿›ç¨‹ä¸­æ‰§è¡Œ
        embedding = await loop.run_in_executor(
            self.executor,
            self._embed_sync,
            text
        )
        
        return embedding
    
    def _embed_sync(self, text: str) -> List[float]:
        # Workerè¿›ç¨‹ä¸­æ‰§è¡Œ
        if self.embedding_model is None:
            self.embedding_model = load_embedding_model()
        
        return self.embedding_model.embed_query(text)
```

**é€‚ç”¨åœºæ™¯**:
- QPS > 100
- éœ€è¦CPUéš”ç¦»
- å¤šç”¨æˆ·å¹¶å‘

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆA (ç¼“å­˜)
   - ä½æˆæœ¬é«˜æ”¶ç›Š
   - å‘½ä¸­ç‡é¢„è®¡40-60%

2. **å‹æµ‹è¯„ä¼°**: 
   ```python
   # æµ‹è¯•ä»£ç 
   import asyncio
   import time
   
   async def test_embedding_latency():
       texts = ["æµ‹è¯•æ–‡æœ¬1", "æµ‹è¯•æ–‡æœ¬2", ...] * 100
       
       start = time.time()
       for text in texts:
           await embedding_model.aembed_query(text)
       elapsed = time.time() - start
       
       print(f"100æ¬¡embedding: {elapsed:.2f}s")
       print(f"å¹³å‡å»¶è¿Ÿ: {elapsed/100*1000:.2f}ms")
   ```

3. **å¦‚æœå¹³å‡å»¶è¿Ÿ>100ms**: è€ƒè™‘æ–¹æ¡ˆB (Workeræ± )

---

### è®¨è®ºç‚¹2: LLMè°ƒç”¨å¹¶è¡ŒåŒ–

**æ‚¨çš„é—®é¢˜**:
> `understand_node` å’Œ `context_node` æ˜¯å¦å¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Ÿ

#### å½“å‰æµç¨‹

```python
# ä¸²è¡Œæ‰§è¡Œ
context_node(state)           # 150-300ms
  â†“
understand_node(state)        # 200-500ms (LLM)
  â†“
route_complexity(state)
```

**æ€»å»¶è¿Ÿ**: 350-800ms

#### ä¾èµ–åˆ†æ

```python
# context_node è¾“å‡º
{
    "enriched_context": {
        "system_prompt": "...",
        "warehouse_info": {...},
        "retrieved_knowledge": [...]
    },
    "user_memory_context": {...}
}

# understand_node è¾“å…¥éœ€æ±‚
- messages (âœ… ç‹¬ç«‹)
- warehouse_code (âœ… å¯æå‰è·å–)
- user_memory_context (âŒ ä¾èµ– context_node)
```

**ç»“è®º**: å­˜åœ¨æ•°æ®ä¾èµ–ï¼Œæ— æ³•å®Œå…¨å¹¶è¡Œ

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: éƒ¨åˆ†å¹¶è¡Œ** (æ¨è)

```python
async def parallel_context_and_understanding(state, *, runtime):
    """å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹éƒ¨åˆ†"""
    
    # å¯å¹¶è¡Œéƒ¨åˆ†
    tasks = [
        # Task 1: ä»“åº“ä¿¡æ¯åŠ è½½
        load_warehouse_info(runtime.context.warehouse_code),
        
        # Task 2: å‘é‡çŸ¥è¯†æ£€ç´¢
        async_load_warehouse_knowledge(runtime.store, ...),
        
        # Task 3: ç”¨æˆ·ç”»åƒåŠ è½½ (profileä¸ä¾èµ–æ¶ˆæ¯å†…å®¹)
        load_user_profile(runtime.store, runtime.context.user_id),
    ]
    
    warehouse_info, knowledge, user_profile = await asyncio.gather(*tasks)
    
    # ä¸²è¡Œéƒ¨åˆ†: è®°å¿†ç­–ç•¥å†³ç­– (ä¾èµ–æ¶ˆæ¯å†…å®¹)
    message = state["messages"][-1].content
    strategy = MemoryRouter.determine_strategy(message)
    
    if strategy == MemoryLoadStrategy.FULL:
        # åŠ è½½å®Œæ•´è®°å¿†
        user_memory = await load_full_memory(runtime.store, user_id)
    else:
        # ä½¿ç”¨å·²åŠ è½½çš„profile
        user_memory = {"profile": user_profile, ...}
    
    # æ„å»ºenriched_context
    enriched_context = build_context(warehouse_info, knowledge)
    
    return {
        "enriched_context": enriched_context,
        "user_memory_context": user_memory
    }
```

**é¢„æœŸæ”¶ç›Š**:
- å»¶è¿Ÿé™ä½30-40%
- ä»350-800ms â†’ 250-550ms

**æ–¹æ¡ˆB: é¢„çƒ­æœºåˆ¶**

```python
class ContextPreloader:
    """ä¸Šä¸‹æ–‡é¢„åŠ è½½å™¨"""
    
    def __init__(self):
        self.preloaded = {}
    
    async def preheat(self, user_id: str, warehouse_code: str):
        """ä¼šè¯å¼€å§‹æ—¶é¢„åŠ è½½"""
        key = f"{user_id}:{warehouse_code}"
        
        # å¹¶è¡Œé¢„åŠ è½½
        self.preloaded[key] = await asyncio.gather(
            load_warehouse_info(warehouse_code),
            load_user_profile(user_id),
            load_frequent_knowledge(warehouse_code)
        )
    
    def get(self, user_id: str, warehouse_code: str):
        key = f"{user_id}:{warehouse_code}"
        return self.preloaded.get(key)

# ä½¿ç”¨åœºæ™¯
# 1. ç”¨æˆ·é¦–æ¬¡å‘æ¶ˆæ¯æ—¶é¢„çƒ­
# 2. å®šæ—¶é¢„çƒ­æ´»è·ƒç”¨æˆ·
# 3. WebSocketè¿æ¥å»ºç«‹æ—¶é¢„çƒ­
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆA (éƒ¨åˆ†å¹¶è¡Œ)
   - æ”¹é€ context_node
   - warehouse_info + knowledgeå¹¶è¡Œ

2. **å¦‚æœæœ‰WebSocket**: æ–¹æ¡ˆB (é¢„çƒ­)
   - è¿æ¥å»ºç«‹æ—¶é¢„åŠ è½½
   - é¦–æ¬¡å“åº”æ¥è¿‘0å»¶è¿Ÿ

3. **ç›‘æ§**:
   ```python
   timing_stats = {
       "context_node_ms": [],
       "understand_node_ms": [],
       "parallel_speedup": 0.0  # å¹¶è¡ŒåŠ é€Ÿæ¯”
   }
   ```

---

### è®¨è®ºç‚¹3: å·¥å…·è°ƒç”¨å»é‡

**æ‚¨çš„é—®é¢˜**:
> ç›¸åŒå‚æ•°çš„å·¥å…·è°ƒç”¨æ˜¯å¦éœ€è¦ç¼“å­˜ï¼Ÿ

#### åœºæ™¯åˆ†æ

```python
# åœºæ™¯1: åŒä¸€ä¼šè¯å†…é‡å¤æŸ¥è¯¢
ç”¨æˆ·: "æ­å·ä»“ä»Šå¤©å…¥åº“é‡ï¼Ÿ"
Agent: query_orders_data(..., "2026-01-28")  # è°ƒç”¨1

ç”¨æˆ·: "å†å…·ä½“è¯´è¯´"
Agent: query_orders_data(..., "2026-01-28")  # è°ƒç”¨2 (ç›¸åŒå‚æ•°!)
```

#### Moltbotçš„åšæ³•

Moltbotæ²¡æœ‰æ˜¾å¼ç¼“å­˜ï¼Œä½†æœ‰ä¼šè¯å†å²ï¼š

```typescript
// Agentå¯ä»¥ä»å†å²ä¸­çœ‹åˆ°ä¹‹å‰çš„å·¥å…·ç»“æœ
const session = {
    messages: [
        { role: 'user', content: 'æ­å·ä»“ä»Šå¤©å…¥åº“é‡?' },
        { role: 'assistant', tool_calls: [...], content: '...' },
        { role: 'tool', tool_call_id: 'xxx', content: '{"data": ...}' },
        { role: 'assistant', content: 'ä»Šå¤©å…¥åº“1000ä»¶' },
    ]
}

// LLMå¯ä»¥ç›´æ¥å¼•ç”¨å†å²ç»“æœï¼Œæ— éœ€é‡æ–°è°ƒç”¨
```

**å¯¹æ¯”**:
- Moltbot: ä¾èµ–LLMç†è§£å†å²
- é£é™©: LLMå¯èƒ½å¿½ç•¥å†å²ç»“æœ

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: å·¥å…·ç»“æœç¼“å­˜** (æ¨è)

```python
from functools import lru_cache
import hashlib

class ToolResultCache:
    """å·¥å…·ç»“æœç¼“å­˜"""
    
    def __init__(self, ttl: int = 300):  # 5åˆ†é’ŸTTL
        self.cache = {}  # {cache_key: (result, expires_at)}
        self.ttl = ttl
    
    def _generate_key(self, tool_name: str, args: dict) -> str:
        """ç”Ÿæˆç¼“å­˜key"""
        # æ’åºå‚æ•°ä¿è¯ä¸€è‡´æ€§
        sorted_args = json.dumps(args, sort_keys=True)
        key_str = f"{tool_name}:{sorted_args}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, tool_name: str, args: dict) -> Optional[Any]:
        key = self._generate_key(tool_name, args)
        
        if key in self.cache:
            result, expires_at = self.cache[key]
            
            # æ£€æŸ¥è¿‡æœŸ
            if time.time() < expires_at:
                return result
            else:
                del self.cache[key]
        
        return None
    
    def set(self, tool_name: str, args: dict, result: Any):
        key = self._generate_key(tool_name, args)
        self.cache[key] = (result, time.time() + self.ttl)

# åœ¨ step_node / reason_node ä½¿ç”¨
tool_cache = ToolResultCache(ttl=300)

async def execute_tool_with_cache(tool_name, args):
    # 1. æŸ¥ç¼“å­˜
    cached = tool_cache.get(tool_name, args)
    if cached is not None:
        writer({"type": "progress", "message": "ä½¿ç”¨ç¼“å­˜ç»“æœ"})
        return cached
    
    # 2. æ‰§è¡Œå·¥å…·
    result = await tool.ainvoke(args)
    
    # 3. å†™ç¼“å­˜
    tool_cache.set(tool_name, args, result)
    
    return result
```

**ç¼“å­˜ç­–ç•¥**:
| å·¥å…·ç±»å‹ | TTL | è¯´æ˜ |
|---------|-----|------|
| å®æ—¶çŠ¶æ€ | 30s | å®æ—¶æ•°æ®å¿«é€Ÿè¿‡æœŸ |
| å†å²æ•°æ® | 5min | å†å²æ•°æ®ç›¸å¯¹ç¨³å®š |
| çŸ¥è¯†å›¾è°± | 10min | ä»“åº“ç»“æ„å˜åŒ–æ…¢ |

**æ–¹æ¡ˆB: æ™ºèƒ½ç¼“å­˜åˆ¤æ–­**

```python
def should_cache_tool(tool_name: str, args: dict) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜"""
    
    # ä¸ç¼“å­˜å®æ—¶çŠ¶æ€æŸ¥è¯¢
    realtime_tools = [
        "get_stage_current_status",
        "get_warehouse_realtime_overview"
    ]
    if tool_name in realtime_tools:
        return False
    
    # ä¸ç¼“å­˜å½“å¤©æ•°æ® (å¯èƒ½å®æ—¶æ›´æ–°)
    if "date" in args:
        date_str = args["date"]
        if date_str == datetime.now().strftime("%Y-%m-%d"):
            return False
    
    # å…¶ä»–éƒ½ç¼“å­˜
    return True
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆA (åŸºç¡€ç¼“å­˜)
   - TTLå·®å¼‚åŒ–é…ç½®
   - ç›‘æ§å‘½ä¸­ç‡

2. **1å‘¨å†…**: æ–¹æ¡ˆB (æ™ºèƒ½åˆ¤æ–­)
   - å®æ—¶å·¥å…·ä¸ç¼“å­˜
   - å½“å¤©æ•°æ®ä¸ç¼“å­˜

3. **ç›‘æ§æŒ‡æ ‡**:
   ```python
   cache_stats = {
       "tool_calls_total": 0,
       "cache_hits": 0,
       "cache_misses": 0,
       "hit_rate": 0.0,
       "avg_latency_cache_hit": 0.0,    # ~5ms
       "avg_latency_cache_miss": 0.0,   # ~200ms
       "estimated_savings_ms": 0.0
   }
   ```

---

## è®°å¿†ç³»ç»Ÿè®¨è®º

### è®¨è®ºç‚¹1: åå¥½å†²çªå¤„ç†

**æ‚¨çš„é—®é¢˜**:
> ç”¨æˆ·å†å²åå¥½ä¸å½“å‰è¯·æ±‚å†²çªæ—¶å¦‚ä½•å¤„ç†ï¼Ÿ

#### åœºæ™¯ç¤ºä¾‹

```
# å†å²åå¥½
UserProfile.preferences = [
    {
        "type": "data_format",
        "content": "ä½¿ç”¨è¡¨æ ¼æ ¼å¼å±•ç¤ºæ•°æ®",
        "created_at": "2026-01-20"
    }
]

# å½“å‰è¯·æ±‚
ç”¨æˆ·: "ç”¨æ–‡å­—æè¿°ä¸€ä¸‹ä»Šå¤©çš„æ•°æ®ï¼Œä¸è¦ç”¨è¡¨æ ¼"
```

#### Moltbotçš„åšæ³•

```typescript
// Moltbotçš„ç³»ç»Ÿæç¤ºè¯ä¼˜å…ˆçº§
const systemPrompt = `
You are an AI assistant.

## User Preferences (ä»StoreåŠ è½½)
- åå¥½1
- åå¥½2

## Current Request Context (å½“å‰æ¶ˆæ¯)
- è¯·æ±‚ç»†èŠ‚

âš ï¸ Priority: Current request overrides stored preferences.
`;
```

**ç­–ç•¥**: æ˜ç¡®å‘ŠçŸ¥LLMä¼˜å…ˆçº§

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: æ˜ç¡®ä¼˜å…ˆçº§è§„åˆ™** (æ¨è)

```python
def build_user_aware_prompt_section(user_memory: UserMemoryContext) -> str:
    """æ„å»ºç”¨æˆ·æ„ŸçŸ¥æç¤ºè¯"""
    
    preferences = user_memory.get("profile", {}).get("preferences", [])
    
    if not preferences:
        return ""
    
    prompt = """
## ğŸ‘¤ ç”¨æˆ·åå¥½è®¾ç½®

ä»¥ä¸‹æ˜¯ç”¨æˆ·çš„å†å²åå¥½ï¼Œè¯·åœ¨å›ç­”æ—¶å‚è€ƒï¼š

"""
    for pref in preferences:
        prompt += f"- **{pref['type']}**: {pref['content']}\n"
    
    prompt += """
âš ï¸ **ä¼˜å…ˆçº§è§„åˆ™**:
1. å¦‚æœç”¨æˆ·å½“å‰æ¶ˆæ¯æ˜ç¡®æå‡ºä¸åŒè¦æ±‚ï¼Œ**ä»¥å½“å‰æ¶ˆæ¯ä¸ºå‡†**
2. å¦‚æœå½“å‰æ¶ˆæ¯æœªæåŠï¼Œå‚è€ƒå†å²åå¥½
3. å¦‚æœå‘ç°åå¥½å†²çªï¼Œè¯¢é—®ç”¨æˆ·ç¡®è®¤

ç¤ºä¾‹:
- å†å²åå¥½: "ä½¿ç”¨è¡¨æ ¼"
- å½“å‰æ¶ˆæ¯: "ç”¨æ–‡å­—æè¿°"
- å¤„ç†: ä½¿ç”¨æ–‡å­—æè¿°ï¼Œå¹¶å¯ä»¥æç¤º"æ£€æµ‹åˆ°æ‚¨ä¹‹å‰åå¥½è¡¨æ ¼ï¼Œæœ¬æ¬¡æŒ‰æ‚¨çš„è¦æ±‚ä½¿ç”¨æ–‡å­—æè¿°"
"""
    return prompt
```

**æ–¹æ¡ˆB: åå¥½ç‰ˆæœ¬æ§åˆ¶**

```python
class PreferenceVersion:
    """åå¥½ç‰ˆæœ¬ç®¡ç†"""
    
    @dataclass
    class Preference:
        type: str
        content: str
        created_at: datetime
        overridden_at: Optional[datetime] = None
        override_reason: Optional[str] = None
    
    async def override_preference(
        self,
        user_id: str,
        pref_type: str,
        new_value: str,
        reason: str
    ):
        """è¦†ç›–åå¥½"""
        profile = await self.store.aget(("user_profile", user_id))
        
        # æ‰¾åˆ°è¦è¦†ç›–çš„åå¥½
        for pref in profile["preferences"]:
            if pref["type"] == pref_type:
                pref["overridden_at"] = datetime.now().isoformat()
                pref["override_reason"] = reason
        
        # æ·»åŠ æ–°åå¥½
        profile["preferences"].append({
            "type": pref_type,
            "content": new_value,
            "created_at": datetime.now().isoformat()
        })
        
        await self.store.aput(("user_profile", user_id), profile)

# ä½¿ç”¨
await pref_version.override_preference(
    user_id="user_123",
    pref_type="data_format",
    new_value="ä½¿ç”¨æ–‡å­—æè¿°",
    reason="ç”¨æˆ·å½“å‰è¯·æ±‚æ˜ç¡®è¦æ±‚"
)
```

**æ–¹æ¡ˆC: åå¥½ç½®ä¿¡åº¦**

```python
class Preference(TypedDict):
    type: str
    content: str
    confidence: float  # 0.0-1.0ï¼Œæ–°å¢å­—æ®µ
    source: Literal["explicit", "implicit"]
    created_at: str

# å†²çªè§£å†³
def resolve_conflict(
    stored_pref: Preference,
    current_request: str
) -> Preference:
    """è§£å†³åå¥½å†²çª"""
    
    # æ˜¾å¼å£°æ˜ > éšå¼æ¨æ–­
    if stored_pref["source"] == "explicit":
        # é«˜ç½®ä¿¡åº¦å†å²åå¥½ï¼Œæç¤ºç”¨æˆ·
        return stored_pref
    
    # éšå¼æ¨æ–­ï¼Œå½“å‰è¯·æ±‚ä¼˜å…ˆ
    return extract_preference_from_message(current_request)
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆA (ä¼˜å…ˆçº§è§„åˆ™)
   - åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­æ˜ç¡®
   - LLMç†è§£èƒ½åŠ›å¼º

2. **1å‘¨å†…**: å¢åŠ å†²çªæ£€æµ‹
   ```python
   def detect_preference_conflict(
       stored_prefs: List[Preference],
       current_message: str
   ) -> Optional[dict]:
       """æ£€æµ‹åå¥½å†²çª"""
       # æå–å½“å‰æ¶ˆæ¯ä¸­çš„éšå¼åå¥½
       # ä¸å†å²åå¥½å¯¹æ¯”
       # è¿”å›å†²çªè¯¦æƒ…
   ```

3. **ç›‘æ§**: è®°å½•å†²çªå‘ç”Ÿé¢‘ç‡
   ```python
   conflict_stats = {
       "total_requests": 0,
       "conflicts_detected": 0,
       "conflicts_auto_resolved": 0,
       "conflicts_user_confirmed": 0
   }
   ```

---

### è®¨è®ºç‚¹2: è®°å¿†æ·˜æ±°ç­–ç•¥

**æ‚¨çš„é—®é¢˜**:
> å½“å‰ä½¿ç”¨ FIFOï¼Œæ˜¯å¦éœ€è¦åŸºäºé‡è¦æ€§çš„ LRUï¼Ÿ

#### å½“å‰ç­–ç•¥

```python
# user_memory_service.py
MAX_BEHAVIOR_ENTRIES = 100

# FIFOæ·˜æ±°
if len(behavior_entries) >= MAX_BEHAVIOR_ENTRIES:
    behavior_entries = behavior_entries[-MAX_BEHAVIOR_ENTRIES:]
```

**é—®é¢˜**:
- æ—©æœŸé‡è¦è®°å½•å¯èƒ½è¢«æ·˜æ±°
- æ— æ³•åŒºåˆ†è®°å¿†é‡è¦æ€§

#### Moltbotçš„åšæ³•

```typescript
// Moltbotä½¿ç”¨æ‘˜è¦å‹ç¼©
async compactSession(session: Session) {
    // å‰åŠéƒ¨åˆ†ç”Ÿæˆæ‘˜è¦
    const oldMessages = session.messages.slice(0, length / 2);
    const summary = await generateSummary(oldMessages);
    
    // ä¿ç•™æ‘˜è¦ + ååŠéƒ¨åˆ†
    session.messages = [
        { role: 'system', content: `Summary: ${summary}` },
        ...session.messages.slice(length / 2)
    ];
}
```

**å¯¹æ¯”**:
- Moltbot: æ‘˜è¦å‹ç¼©ï¼Œä¿¡æ¯å¯†åº¦é«˜
- æ‚¨çš„æ–¹æ¡ˆ: æˆªæ–­ï¼Œç®€å•ä½†å¯èƒ½ä¸¢å¤±ä¿¡æ¯

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: é‡è¦æ€§è¯„åˆ† + LRU** (æ¨è)

```python
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ScoredBehaviorEntry:
    """å¸¦è¯„åˆ†çš„è¡Œä¸ºè®°å½•"""
    entry: dict
    score: float
    last_accessed: datetime

class ImportanceBasedMemoryManager:
    """åŸºäºé‡è¦æ€§çš„è®°å¿†ç®¡ç†"""
    
    def calculate_importance(self, entry: dict) -> float:
        """è®¡ç®—è®°å¿†é‡è¦æ€§ (0-1)"""
        score = 0.0
        
        # å› ç´ 1: è®°å½•ç±»å‹æƒé‡
        type_weights = {
            "tool_usage": 0.3,        # å·¥å…·ä½¿ç”¨
            "preference": 0.8,        # æ˜¾å¼åå¥½
            "conclusion": 0.9,        # é‡è¦ç»“è®º
            "question": 0.4,          # é—®é¢˜è®°å½•
        }
        score += type_weights.get(entry.get("type"), 0.5)
        
        # å› ç´ 2: è®¿é—®é¢‘ç‡
        access_count = entry.get("access_count", 0)
        score += min(access_count * 0.1, 0.3)
        
        # å› ç´ 3: æ—¶é—´è¡°å‡
        days_old = (datetime.now() - entry["created_at"]).days
        decay = 0.95 ** (days_old / 30)  # æ¯30å¤©è¡°å‡5%
        score *= decay
        
        return min(score, 1.0)
    
    def evict(self, entries: List[dict], max_size: int) -> List[dict]:
        """æ·˜æ±°ä½ä»·å€¼è®°å¿†"""
        # 1. è®¡ç®—è¯„åˆ†
        scored = [
            ScoredBehaviorEntry(
                entry=e,
                score=self.calculate_importance(e),
                last_accessed=e.get("last_accessed", e["created_at"])
            )
            for e in entries
        ]
        
        # 2. æŒ‰è¯„åˆ†æ’åº (é«˜åˆ†ä¼˜å…ˆä¿ç•™)
        scored.sort(key=lambda x: x.score, reverse=True)
        
        # 3. ä¿ç•™top-N
        return [s.entry for s in scored[:max_size]]
```

**æ–¹æ¡ˆB: åˆ†å±‚å­˜å‚¨**

```python
class TieredMemoryStorage:
    """åˆ†å±‚è®°å¿†å­˜å‚¨"""
    
    def __init__(self):
        self.hot = []   # æœ€è¿‘100æ¡ï¼Œå¿«é€Ÿè®¿é—®
        self.warm = []  # 100-500æ¡ï¼ŒæŒ‰éœ€åŠ è½½
        self.cold = []  # 500+æ¡ï¼Œå½’æ¡£å‹ç¼©
    
    async def add_entry(self, entry: dict):
        self.hot.append(entry)
        
        # Hotæ»¡äº† â†’ ç§»åŠ¨åˆ°Warm
        if len(self.hot) > 100:
            to_move = self.hot[:50]  # ç§»åŠ¨å‰50æ¡
            self.hot = self.hot[50:]
            self.warm.extend(to_move)
        
        # Warmæ»¡äº† â†’ å‹ç¼©åˆ°Cold
        if len(self.warm) > 400:
            to_compress = self.warm[:200]
            self.warm = self.warm[200:]
            
            # ç”Ÿæˆæ‘˜è¦
            summary = await self.summarize_entries(to_compress)
            self.cold.append(summary)
    
    async def search(self, query: str, tier: str = "hot"):
        """æŒ‰å±‚æœç´¢"""
        if tier == "hot":
            return self._search_in(self.hot, query)
        elif tier == "warm":
            return self._search_in(self.hot + self.warm, query)
        else:  # all
            return self._search_all_tiers(query)
```

**æ–¹æ¡ˆC: å€Ÿé‰´Moltbotçš„æ‘˜è¦ç­–ç•¥**

```python
async def compact_user_memory(user_id: str, store: BaseStore):
    """å‹ç¼©ç”¨æˆ·è®°å¿†"""
    activity = await store.aget(("user_activity", user_id))
    entries = activity["behavior_entries"]
    
    if len(entries) <= 100:
        return  # æ— éœ€å‹ç¼©
    
    # 1. åˆ†ç»„ (æŒ‰æ—¶é—´/ç±»å‹)
    old_entries = entries[:50]
    recent_entries = entries[50:]
    
    # 2. ç”Ÿæˆæ‘˜è¦
    summary = await generate_activity_summary(old_entries)
    
    # 3. æ›¿æ¢
    activity["behavior_entries"] = [{
        "type": "summary",
        "content": summary,
        "summarized_count": len(old_entries),
        "created_at": datetime.now().isoformat()
    }] + recent_entries
    
    await store.aput(("user_activity", user_id), activity)
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **çŸ­æœŸ** (1å‘¨): æ–¹æ¡ˆA (é‡è¦æ€§è¯„åˆ†)
   - å®æ–½ç®€å•
   - æ•ˆæœæ˜¾è‘—

2. **ä¸­æœŸ** (1æœˆ): æ–¹æ¡ˆC (æ‘˜è¦å‹ç¼©)
   - ä¿¡æ¯å¯†åº¦é«˜
   - å­¦ä¹ Moltbot

3. **ç›‘æ§**:
   ```python
   memory_health = {
       "avg_entries_per_user": 0,
       "users_above_threshold": 0,
       "eviction_count": 0,
       "important_entries_evicted": 0  # é«˜åˆ†è¢«æ·˜æ±° (éœ€ä¼˜åŒ–)
   }
   ```

---

### è®¨è®ºç‚¹3: è·¨ä»“åº“è®°å¿†å…±äº«

**æ‚¨çš„é—®é¢˜**:
> ç”¨æˆ·ç®¡ç†å¤šä¸ªä»“åº“æ—¶ï¼Œç»éªŒæ˜¯å¦å¯ä»¥è¿ç§»ï¼Ÿ

#### å½“å‰æ¶æ„

```python
# ç”¨æˆ·è®°å¿†æŒ‰ user_id å­˜å‚¨
("user_profile", user_id)      # è·¨ä»“åº“å…±äº« âœ…
("user_activity", user_id)     # è·¨ä»“åº“å…±äº« âœ…

# ä»“åº“è§„åˆ™æŒ‰ warehouse_code å­˜å‚¨
("warehouse_rules", warehouse_code)  # éš”ç¦» âŒ
```

**å·²æ”¯æŒ**: ç”¨æˆ·ç”»åƒå’Œæ´»åŠ¨æ˜¯è·¨ä»“åº“çš„  
**æœªæ”¯æŒ**: ä»“åº“ç»éªŒè¿ç§»

#### Moltbotçš„åšæ³•

```typescript
// Moltbotçš„Agentè·¯ç”±
function selectAgent(warehouseCode: string) {
    // ä¸åŒä»“åº“ä½¿ç”¨ä¸åŒAgentå®ä¾‹
    return agents[warehouseCode] || agents.default;
}

// æ¯ä¸ªAgentæœ‰ç‹¬ç«‹å·¥ä½œç©ºé—´
~/clawd/agents/
â”œâ”€â”€ warehouse_hz/     # æ­å·ä»“Agent
â”œâ”€â”€ warehouse_sh/     # ä¸Šæµ·ä»“Agent
â””â”€â”€ default/          # é»˜è®¤Agent
```

**å¯¹æ¯”**:
- Moltbot: å¼ºéš”ç¦»ï¼Œæ¯ä¸ªä»“åº“ç‹¬ç«‹
- æ‚¨çš„æ–¹æ¡ˆ: ç”¨æˆ·çº§å…±äº«ï¼Œæ›´çµæ´»

**æ‚¨çš„ä¼˜åŠ¿**: è·¨ä»“åº“å­¦ä¹ èƒ½åŠ›ï¼

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: ä»“åº“ç»éªŒè¿ç§»** (åˆ›æ–°åŠŸèƒ½)

```python
class CrossWarehouseExperienceTransfer:
    """è·¨ä»“åº“ç»éªŒè¿ç§»"""
    
    async def transfer_insights(
        self,
        from_warehouse: str,
        to_warehouse: str,
        similarity_threshold: float = 0.7
    ):
        """è¿ç§»ç›¸ä¼¼ä»“åº“çš„ç»éªŒ"""
        
        # 1. è®¡ç®—ä»“åº“ç›¸ä¼¼åº¦
        similarity = await self.calculate_warehouse_similarity(
            from_warehouse, to_warehouse
        )
        
        if similarity < similarity_threshold:
            return None
        
        # 2. æå–å¯è¿ç§»çš„insights
        from_rules = await self.store.aget(("warehouse_rules", from_warehouse))
        
        transferable = []
        for rule in from_rules:
            if rule.get("transferable", False):  # æ ‡è®°å¯è¿ç§»
                transferable.append({
                    "content": rule["content"],
                    "confidence": similarity,  # ç½®ä¿¡åº¦
                    "source_warehouse": from_warehouse
                })
        
        # 3. å†™å…¥ç›®æ ‡ä»“åº“ (å¸¦æ¥æºæ ‡è®°)
        to_rules = await self.store.aget(("warehouse_rules", to_warehouse))
        to_rules["transferred_insights"] = transferable
        
        await self.store.aput(("warehouse_rules", to_warehouse), to_rules)
    
    async def calculate_warehouse_similarity(
        self,
        wh1: str,
        wh2: str
    ) -> float:
        """è®¡ç®—ä»“åº“ç›¸ä¼¼åº¦"""
        # åŸºäºä»“åº“ç‰¹å¾è®¡ç®—
        info1 = await get_warehouse_info(wh1)
        info2 = await get_warehouse_info(wh2)
        
        # å› ç´ 1: ä¸šåŠ¡æ–¹å‘ç›¸ä¼¼åº¦
        direction_match = info1["direction"] == info2["direction"]
        
        # å› ç´ 2: ç¯èŠ‚ç›¸ä¼¼åº¦
        stages1 = set(info1["stages"])
        stages2 = set(info2["stages"])
        stage_similarity = len(stages1 & stages2) / len(stages1 | stages2)
        
        # å› ç´ 3: è§„æ¨¡ç›¸ä¼¼åº¦
        scale_diff = abs(info1["avg_volume"] - info2["avg_volume"]) / max(...)
        scale_similarity = 1 - min(scale_diff, 1.0)
        
        # ç»¼åˆ
        return 0.4 * direction_match + 0.4 * stage_similarity + 0.2 * scale_similarity
```

**ä½¿ç”¨åœºæ™¯**:
```python
# ç”¨æˆ·é¦–æ¬¡ä½¿ç”¨æ–°ä»“åº“æ—¶
if is_first_time_warehouse(user_id, warehouse_code):
    # æŸ¥æ‰¾ç”¨æˆ·ç®¡ç†çš„ç›¸ä¼¼ä»“åº“
    similar_wh = find_similar_managed_warehouse(user_id, warehouse_code)
    
    if similar_wh:
        await transfer_insights(similar_wh, warehouse_code)
        
        # æç¤ºç”¨æˆ·
        await send_message(
            f"æ£€æµ‹åˆ°æ‚¨ç®¡ç†çš„{similar_wh}ä¸{warehouse_code}ç›¸ä¼¼(ç›¸ä¼¼åº¦80%)ï¼Œ"
            f"å·²è‡ªåŠ¨è¿ç§»ç›¸å…³ç»éªŒä¾›å‚è€ƒ"
        )
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ä¿æŒç°çŠ¶**: è·¨ä»“åº“ç”¨æˆ·ç”»åƒå·²ç»å¾ˆå¥½

2. **å¯é€‰å¢å¼º**: æ–¹æ¡ˆA (ç»éªŒè¿ç§»)
   - åˆ›æ–°åŠŸèƒ½
   - æå‡æ–°ä»“åº“é¦–æ¬¡ä½¿ç”¨ä½“éªŒ

3. **å®æ–½æ­¥éª¤**:
   ```
   Week 1: ä»“åº“ç›¸ä¼¼åº¦è®¡ç®—
   Week 2: å¯è¿ç§»è§„åˆ™æ ‡è®°
   Week 3: è¿ç§»é€»è¾‘å®ç°
   Week 4: ç”¨æˆ·åé¦ˆæ”¶é›†
   ```

---

## å¯è§‚æµ‹æ€§è®¨è®º

### è®¨è®ºç‚¹1: èŠ‚ç‚¹çº§åˆ«è¿½è¸ª

**æ‚¨çš„é—®é¢˜**:
> æ˜¯å¦éœ€è¦ä¸ºæ¯ä¸ªèŠ‚ç‚¹æ·»åŠ ç‹¬ç«‹çš„ trace_idï¼Ÿ

#### å½“å‰çŠ¶æ€

```python
# æ‚¨æœ‰åŸºç¡€ç»Ÿè®¡
self.stats = {
    "requests_processed": 0,
    "total_response_time": 0.0,
    "errors": 0
}
```

**é—®é¢˜**:
- âŒ æ— æ³•è¿½è¸ªå•ä¸ªè¯·æ±‚çš„å®Œæ•´é“¾è·¯
- âŒ æ— æ³•åˆ†æèŠ‚ç‚¹çº§æ€§èƒ½ç“¶é¢ˆ
- âŒ éš¾ä»¥è°ƒè¯•å¤æ‚é—®é¢˜

#### Moltbotçš„å¯è§‚æµ‹æ€§

Moltbotæ²¡æœ‰å†…ç½®è¿½è¸ªï¼Œä½†æ¶æ„æ”¯æŒï¼š

```typescript
// Gatewayçš„äº‹ä»¶æ¨é€æœºåˆ¶
gateway.broadcast({
    type: "agent.node.start",
    payload: {
        sessionKey: "xxx",
        node: "understand_node",
        traceId: "trace-123",
        timestamp: Date.now()
    }
});
```

#### æ”¹è¿›æ–¹æ¡ˆ

**æ–¹æ¡ˆA: ç®€å•Traceç³»ç»Ÿ** (æ¨è)

```python
import uuid
from contextvars import ContextVar

# ä½¿ç”¨ContextVarä¼ é€’trace_id
current_trace_id: ContextVar[str] = ContextVar('trace_id', default=None)

class TraceManager:
    """ç®€å•çš„è¿½è¸ªç®¡ç†å™¨"""
    
    def __init__(self):
        self.traces = {}  # {trace_id: TraceData}
    
    def start_trace(self, user_id: str, message: str) -> str:
        """å¼€å§‹è¿½è¸ª"""
        trace_id = f"trace_{uuid.uuid4().hex[:12]}"
        
        self.traces[trace_id] = {
            "trace_id": trace_id,
            "user_id": user_id,
            "message": message,
            "started_at": time.time(),
            "nodes": [],
            "status": "running"
        }
        
        # è®¾ç½®åˆ°context
        current_trace_id.set(trace_id)
        
        return trace_id
    
    def log_node_start(self, node_name: str):
        """è®°å½•èŠ‚ç‚¹å¼€å§‹"""
        trace_id = current_trace_id.get()
        if not trace_id:
            return
        
        trace = self.traces[trace_id]
        trace["nodes"].append({
            "node": node_name,
            "started_at": time.time(),
            "status": "running"
        })
    
    def log_node_end(self, node_name: str, result: Any = None):
        """è®°å½•èŠ‚ç‚¹ç»“æŸ"""
        trace_id = current_trace_id.get()
        if not trace_id:
            return
        
        trace = self.traces[trace_id]
        for node in reversed(trace["nodes"]):
            if node["node"] == node_name and node["status"] == "running":
                node["status"] = "completed"
                node["ended_at"] = time.time()
                node["duration_ms"] = (node["ended_at"] - node["started_at"]) * 1000
                break
    
    def get_trace(self, trace_id: str) -> dict:
        """è·å–è¿½è¸ªè¯¦æƒ…"""
        return self.traces.get(trace_id)

# å…¨å±€å®ä¾‹
trace_manager = TraceManager()

# åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨
async def understand_node(state, *, runtime):
    trace_manager.log_node_start("understand_node")
    
    try:
        # èŠ‚ç‚¹é€»è¾‘
        result = await _do_understanding(...)
        return result
    finally:
        trace_manager.log_node_end("understand_node", result)
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
# APIå±‚
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    # å¼€å§‹è¿½è¸ª
    trace_id = trace_manager.start_trace(request.user_id, request.message)
    
    try:
        # æ‰§è¡Œ
        result = await agent.ainvoke(...)
        
        # å®Œæˆè¿½è¸ª
        trace = trace_manager.get_trace(trace_id)
        
        return {
            "response": result,
            "trace_id": trace_id,
            "performance": {
                "total_ms": trace["total_ms"],
                "nodes": trace["nodes"]
            }
        }
    except Exception as e:
        trace_manager.log_error(trace_id, e)
        raise
```

**è¿½è¸ªæ•°æ®ç¤ºä¾‹**:
```json
{
  "trace_id": "trace_a1b2c3d4",
  "user_id": "user_123",
  "message": "å¯¹æ¯”æœ¬å‘¨å’Œä¸Šå‘¨å…¥åº“è¶‹åŠ¿",
  "started_at": 1706400000.0,
  "total_ms": 12500,
  "status": "completed",
  "nodes": [
    {
      "node": "context_node",
      "started_at": 1706400000.1,
      "ended_at": 1706400000.3,
      "duration_ms": 200,
      "status": "completed"
    },
    {
      "node": "understand_node",
      "duration_ms": 450,
      "status": "completed"
    },
    {
      "node": "plan_node",
      "duration_ms": 800,
      "status": "completed"
    },
    {
      "node": "step_node",
      "duration_ms": 3500,
      "loop_count": 3,
      "status": "completed"
    },
    {
      "node": "synthesize_node",
      "duration_ms": 7550,
      "status": "completed"
    }
  ]
}
```

**æ–¹æ¡ˆB: LangSmithé›†æˆ** (ä¸“ä¸šæ–¹æ¡ˆ)

```python
# å®˜æ–¹LangSmithè¿½è¸ª
from langsmith import Client

client = Client()

# LangGraphè‡ªåŠ¨é›†æˆ
graph = workflow.compile(
    checkpointer=checkpointer,
    store=store,
    debug=True  # å¯ç”¨è¿½è¸ª
)

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "..."
os.environ["LANGCHAIN_PROJECT"] = "conversation-agent"
```

**LangSmithä¼˜åŠ¿**:
- âœ… å…¨è‡ªåŠ¨è¿½è¸ª(æ— éœ€æ”¹ä»£ç )
- âœ… å¯è§†åŒ–è°ƒè¯•ç•Œé¢
- âœ… æ€§èƒ½åˆ†ææŠ¥å‘Š
- âœ… é”™è¯¯è‡ªåŠ¨èšåˆ

**æˆæœ¬**:
- å•†ä¸šäº§å“ï¼Œæœ‰è´¹ç”¨
- ä¾èµ–å¤–éƒ¨æœåŠ¡

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆA (ç®€å•Trace)
   - 2å¤©å®ç°
   - æ»¡è¶³åŸºæœ¬éœ€æ±‚

2. **1æœˆå†…**: è¯„ä¼°æ–¹æ¡ˆB (LangSmith)
   - è¯•ç”¨å…è´¹tier
   - è¯„ä¼°ROI

3. **ç›‘æ§Dashboard**:
   ```python
   # å®æ—¶æ€§èƒ½ç›‘æ§
   performance_dashboard = {
       "p50_latency_ms": 0,
       "p95_latency_ms": 0,
       "p99_latency_ms": 0,
       "slowest_node": "",
       "node_latencies": {
           "context_node": [],
           "understand_node": [],
           ...
       }
   }
   ```

---

### è®¨è®ºç‚¹2: ç”¨æˆ·æ„å›¾åˆ†å¸ƒç»Ÿè®¡

**æ‚¨çš„é—®é¢˜**:
> æ˜¯å¦éœ€è¦æ”¶é›† intent åˆ†å¸ƒç”¨äºæ¨¡å‹å¾®è°ƒï¼Ÿ

#### ä»·å€¼åˆ†æ

**æ”¶é›†æ„å›¾åˆ†å¸ƒçš„ç”¨é€”**:
1. âœ… ä¼˜åŒ–understand_nodeæç¤ºè¯
2. âœ… è¯†åˆ«é«˜é¢‘åœºæ™¯é’ˆå¯¹æ€§ä¼˜åŒ–
3. âœ… è®­ç»ƒåˆ†ç±»æ¨¡å‹(æ›¿ä»£LLMåˆ¤æ–­)
4. âœ… äº§å“åŠŸèƒ½ä¼˜å…ˆçº§å†³ç­–

#### å®æ–½æ–¹æ¡ˆ

**æ–¹æ¡ˆA: åŸºç¡€ç»Ÿè®¡** (ç«‹å³å®æ–½)

```python
class IntentStatistics:
    """æ„å›¾ç»Ÿè®¡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.stats = {
            "intent_distribution": defaultdict(int),
            "intent_by_hour": defaultdict(lambda: defaultdict(int)),
            "intent_avg_latency": defaultdict(list),
            "intent_success_rate": defaultdict(lambda: {"success": 0, "fail": 0})
        }
    
    def record(
        self,
        intent: str,
        latency_ms: float,
        success: bool,
        hour: int
    ):
        # åˆ†å¸ƒç»Ÿè®¡
        self.stats["intent_distribution"][intent] += 1
        
        # æ—¶æ®µç»Ÿè®¡
        self.stats["intent_by_hour"][hour][intent] += 1
        
        # å»¶è¿Ÿç»Ÿè®¡
        self.stats["intent_avg_latency"][intent].append(latency_ms)
        
        # æˆåŠŸç‡
        key = "success" if success else "fail"
        self.stats["intent_success_rate"][intent][key] += 1
    
    def get_report(self) -> dict:
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        total = sum(self.stats["intent_distribution"].values())
        
        report = {}
        for intent, count in self.stats["intent_distribution"].items():
            latencies = self.stats["intent_avg_latency"][intent]
            success_data = self.stats["intent_success_rate"][intent]
            
            report[intent] = {
                "count": count,
                "percentage": count / total,
                "avg_latency_ms": sum(latencies) / len(latencies) if latencies else 0,
                "success_rate": success_data["success"] / (success_data["success"] + success_data["fail"])
            }
        
        return report

# å…¨å±€å®ä¾‹
intent_stats = IntentStatistics()

# åœ¨ understand_node è®°å½•
async def understand_node(state, *, runtime):
    start_time = time.time()
    
    try:
        understanding = await _do_understanding(...)
        
        # è®°å½•æˆåŠŸ
        intent_stats.record(
            intent=understanding["intent"],
            latency_ms=(time.time() - start_time) * 1000,
            success=True,
            hour=datetime.now().hour
        )
        
        return {"understanding": understanding}
    except Exception as e:
        # è®°å½•å¤±è´¥
        intent_stats.record(
            intent="unknown",
            latency_ms=(time.time() - start_time) * 1000,
            success=False,
            hour=datetime.now().hour
        )
        raise
```

**æŠ¥å‘Šç¤ºä¾‹**:
```json
{
  "query_data": {
    "count": 450,
    "percentage": 0.45,
    "avg_latency_ms": 350,
    "success_rate": 0.98,
    "peak_hours": [9, 10, 14, 15]
  },
  "analyze_trend": {
    "count": 280,
    "percentage": 0.28,
    "avg_latency_ms": 5200,
    "success_rate": 0.92,
    "peak_hours": [10, 16]
  },
  ...
}
```

**æ–¹æ¡ˆB: ç”¨æˆ·åé¦ˆæ”¶é›†** (é—­ç¯ä¼˜åŒ–)

```python
class IntentFeedbackCollector:
    """æ„å›¾åé¦ˆæ”¶é›†"""
    
    async def collect_feedback(
        self,
        trace_id: str,
        user_feedback: Literal["good", "bad", "wrong_intent"]
    ):
        """æ”¶é›†ç”¨æˆ·åé¦ˆ"""
        trace = trace_manager.get_trace(trace_id)
        
        # è®°å½•åé¦ˆ
        await self.store.aput(
            ("intent_feedback", trace_id),
            {
                "message": trace["message"],
                "predicted_intent": trace["understanding"]["intent"],
                "user_feedback": user_feedback,
                "timestamp": datetime.now().isoformat()
            }
        )
        
        # å¦‚æœæ˜¯è¯¯åˆ¤ï¼Œè®°å½•æ ·æœ¬
        if user_feedback == "wrong_intent":
            await self.save_misclassification_sample(trace)

# APIæ¥å£
@app.post("/feedback")
async def submit_feedback(
    trace_id: str,
    feedback: str,
    correct_intent: Optional[str] = None
):
    await feedback_collector.collect_feedback(trace_id, feedback)
    
    if correct_intent:
        # ç”¨æˆ·æä¾›æ­£ç¡®æ„å›¾ï¼Œè®°å½•ä¸ºè®­ç»ƒæ ·æœ¬
        await feedback_collector.save_training_sample(trace_id, correct_intent)
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆA (åŸºç¡€ç»Ÿè®¡)
   - 1å¤©å®ç°
   - æŒç»­æ”¶é›†æ•°æ®

2. **2å‘¨å†…**: ç”Ÿæˆé¦–ä»½æŠ¥å‘Š
   - åˆ†æé«˜é¢‘æ„å›¾
   - è¯†åˆ«ä¼˜åŒ–é‡ç‚¹

3. **1æœˆå†…**: æ–¹æ¡ˆB (åé¦ˆæ”¶é›†)
   - æ·»åŠ åé¦ˆæŒ‰é’®
   - æ”¶é›†è¯¯åˆ¤æ ·æœ¬

4. **3æœˆå†…**: æ¨¡å‹å¾®è°ƒ
   - ç§¯ç´¯1000+æ ‡æ³¨æ ·æœ¬
   - è®­ç»ƒåˆ†ç±»æ¨¡å‹

---

### è®¨è®ºç‚¹3: å·¥å…·å¤±è´¥ç‡ç›‘æ§

**æ‚¨çš„é—®é¢˜**:
> å½“å‰ä»…è®°å½•é”™è¯¯æ•°ï¼Œæ˜¯å¦éœ€è¦æŒ‰å·¥å…·ç±»å‹åˆ†ç±»ï¼Ÿ

#### å½“å‰çŠ¶æ€

```python
self.stats = {
    "errors": 0  # å…¨å±€é”™è¯¯è®¡æ•°
}
```

#### æ”¹è¿›æ–¹æ¡ˆ

**å®Œæ•´çš„å·¥å…·ç›‘æ§ç³»ç»Ÿ**

```python
class ToolMonitoring:
    """å·¥å…·ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        self.tool_stats = defaultdict(lambda: {
            "total_calls": 0,
            "success_calls": 0,
            "failed_calls": 0,
            "latencies_ms": [],
            "error_types": defaultdict(int),
            "last_error": None
        })
    
    async def record_tool_call(
        self,
        tool_name: str,
        args: dict,
        success: bool,
        latency_ms: float,
        error: Optional[Exception] = None
    ):
        """è®°å½•å·¥å…·è°ƒç”¨"""
        stats = self.tool_stats[tool_name]
        
        stats["total_calls"] += 1
        stats["latencies_ms"].append(latency_ms)
        
        if success:
            stats["success_calls"] += 1
        else:
            stats["failed_calls"] += 1
            
            if error:
                error_type = type(error).__name__
                stats["error_types"][error_type] += 1
                stats["last_error"] = {
                    "type": error_type,
                    "message": str(error),
                    "args": args,
                    "timestamp": datetime.now().isoformat()
                }
    
    def get_reliability_report(self) -> dict:
        """ç”Ÿæˆå¯é æ€§æŠ¥å‘Š"""
        report = {}
        
        for tool_name, stats in self.tool_stats.items():
            total = stats["total_calls"]
            success_rate = stats["success_calls"] / total if total > 0 else 0
            
            latencies = stats["latencies_ms"]
            p50 = percentile(latencies, 50) if latencies else 0
            p95 = percentile(latencies, 95) if latencies else 0
            
            report[tool_name] = {
                "total_calls": total,
                "success_rate": success_rate,
                "p50_latency_ms": p50,
                "p95_latency_ms": p95,
                "top_errors": sorted(
                    stats["error_types"].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:3]
            }
        
        # æ’åºï¼šæŒ‰å¤±è´¥ç‡é™åº
        sorted_report = sorted(
            report.items(),
            key=lambda x: 1 - x[1]["success_rate"],
            reverse=True
        )
        
        return dict(sorted_report)

# å…¨å±€å®ä¾‹
tool_monitoring = ToolMonitoring()

# åœ¨ ToolNode / step_node ä½¿ç”¨
async def execute_tool_with_monitoring(tool_name, args):
    start_time = time.time()
    
    try:
        result = await tool.ainvoke(args)
        
        # è®°å½•æˆåŠŸ
        await tool_monitoring.record_tool_call(
            tool_name=tool_name,
            args=args,
            success=True,
            latency_ms=(time.time() - start_time) * 1000
        )
        
        return result
    except Exception as e:
        # è®°å½•å¤±è´¥
        await tool_monitoring.record_tool_call(
            tool_name=tool_name,
            args=args,
            success=False,
            latency_ms=(time.time() - start_time) * 1000,
            error=e
        )
        raise
```

**ç›‘æ§æŠ¥å‘Šç¤ºä¾‹**:
```json
{
  "query_orders_data_by_date_range": {
    "total_calls": 1250,
    "success_rate": 0.98,
    "p50_latency_ms": 180,
    "p95_latency_ms": 450,
    "top_errors": [
      ["DatabaseConnectionError", 15],
      ["TimeoutError", 8],
      ["ValidationError", 2]
    ]
  },
  "get_stage_current_status": {
    "total_calls": 680,
    "success_rate": 0.85,  // âš ï¸ ä½æˆåŠŸç‡!
    "p50_latency_ms": 2100,  // âš ï¸ é«˜å»¶è¿Ÿ!
    "p95_latency_ms": 8500,
    "top_errors": [
      ["GraphQueryTimeout", 45],  // éœ€è¦ä¼˜åŒ–
      ["StageNotFound", 32]
    ]
  }
}
```

**å‘Šè­¦è§„åˆ™**:
```python
def check_tool_health(report: dict) -> List[str]:
    """æ£€æŸ¥å·¥å…·å¥åº·åº¦"""
    alerts = []
    
    for tool_name, stats in report.items():
        # å‘Šè­¦1: æˆåŠŸç‡<90%
        if stats["success_rate"] < 0.9:
            alerts.append(
                f"ğŸ”´ {tool_name} æˆåŠŸç‡ä½: {stats['success_rate']:.1%}"
            )
        
        # å‘Šè­¦2: P95å»¶è¿Ÿ>5s
        if stats["p95_latency_ms"] > 5000:
            alerts.append(
                f"ğŸŸ¡ {tool_name} P95å»¶è¿Ÿé«˜: {stats['p95_latency_ms']:.0f}ms"
            )
        
        # å‘Šè­¦3: ç›¸åŒé”™è¯¯é¢‘å‘
        for error_type, count in stats["top_errors"]:
            if count > 10:
                alerts.append(
                    f"ğŸŸ  {tool_name} é«˜é¢‘é”™è¯¯: {error_type} ({count}æ¬¡)"
                )
    
    return alerts
```

**ğŸ’¡ æœ€ç»ˆå»ºè®®**:

1. **æœ¬å‘¨å®æ–½**: å®Œæ•´å·¥å…·ç›‘æ§ç³»ç»Ÿ
   - 2-3å¤©å¼€å‘
   - é«˜ä»·å€¼ä½æˆæœ¬

2. **æ¯æ—¥æŠ¥å‘Š**: 
   - è‡ªåŠ¨ç”Ÿæˆç›‘æ§æŠ¥å‘Š
   - é‚®ä»¶/é’‰é’‰é€šçŸ¥å‘Šè­¦

3. **å¯è§†åŒ–**: ç®€å•Dashboard
   ```python
   @app.get("/monitoring/tools")
   async def tools_dashboard():
       report = tool_monitoring.get_reliability_report()
       alerts = check_tool_health(report)
       
       return {
           "report": report,
           "alerts": alerts,
           "generated_at": datetime.now().isoformat()
       }
   ```

---

## Moltbotå€Ÿé‰´æ–¹æ¡ˆ

### æ ¸å¿ƒå»ºè®®: æ··åˆæ¶æ„

```
ä¿ç•™æ‚¨çš„ä¼˜åŠ¿:
âœ… LangGraphåŒè·¯å¾„(Standard/Complex)
âœ… ç»†ç²’åº¦èŠ‚ç‚¹æ‹†åˆ†
âœ… ç”¨æˆ·è®°å¿†ç³»ç»Ÿ
âœ… é‡è¯•ç­–ç•¥

å­¦ä¹ Moltbot:
ğŸ“¥ Gatewayæ§åˆ¶å¹³é¢(å¯é€‰ï¼Œå¦‚éœ€å¤šå¹³å°)
ğŸ“¥ Skillæ’ä»¶åŒ–æœºåˆ¶(å¼ºçƒˆæ¨è)
ğŸ“¥ å·¥å…·æƒé™ç­–ç•¥
ğŸ“¥ é…ç½®çƒ­é‡è½½

ä¸éœ€è¦å­¦ä¹ :
âŒ Pi Agent (æ‚¨çš„LangGraphæ›´é€‚åˆä¸šåŠ¡)
âŒ Channelé€‚é…å™¨ (å¦‚æœä¸éœ€è¦å¤šå¹³å°)
âŒ macOS/iOSåº”ç”¨ (éæ ¸å¿ƒéœ€æ±‚)
```

### å®æ–½è·¯çº¿å›¾

```
Phase 1 (Week 1-2): æ€§èƒ½ä¼˜åŒ–
â”œâ”€ å·¥å…·å¹¶è¡ŒåŒ–
â”œâ”€ Embeddingç¼“å­˜
â”œâ”€ å·¥å…·ç»“æœç¼“å­˜
â””â”€ ç®€å•Traceç³»ç»Ÿ

Phase 2 (Week 3-4): ç›‘æ§å®Œå–„
â”œâ”€ æ„å›¾åˆ†å¸ƒç»Ÿè®¡
â”œâ”€ å·¥å…·ç›‘æ§ç³»ç»Ÿ
â”œâ”€ æ€§èƒ½Dashboard
â””â”€ å‘Šè­¦æœºåˆ¶

Phase 3 (Month 2): æ’ä»¶åŒ–
â”œâ”€ Skillæ¥å£å®šä¹‰
â”œâ”€ å·¥å…·åŠ¨æ€åŠ è½½
â”œâ”€ æƒé™ç­–ç•¥
â””â”€ é…ç½®ç®¡ç†ä¼˜åŒ–

Phase 4 (Month 3): å¯é€‰æ‰©å±•
â”œâ”€ Gateway(å¦‚éœ€å¤šå¹³å°)
â”œâ”€ å¤šAgentåä½œ
â”œâ”€ LangSmithé›†æˆ
â””â”€ ç§»åŠ¨ç«¯æ”¯æŒ
```

---

## æ€»ç»“

æ‚¨çš„Conversation Agentå·²ç»æ˜¯**ç”Ÿäº§çº§çš„LangGraphå®ç°**ï¼Œåœ¨å·¥ä½œæµè®¾è®¡å’Œè®°å¿†ç³»ç»Ÿä¸Šç”šè‡³**è¶…è¶ŠMoltbot**ã€‚

**æ ¸å¿ƒä¼˜åŠ¿**:
1. âœ… åŒè·¯å¾„ä¼˜åŒ–
2. âœ… ç»†ç²’åº¦èŠ‚ç‚¹æ‹†åˆ†
3. âœ… å®Œå–„çš„é‡è¯•ç­–ç•¥
4. âœ… å…ˆè¿›çš„ç”¨æˆ·è®°å¿†ç³»ç»Ÿ

**å€¼å¾—æ”¹è¿›**:
1. ğŸ“Š å¯è§‚æµ‹æ€§(è¿½è¸ªã€ç›‘æ§ã€ç»Ÿè®¡)
2. âš¡ æ€§èƒ½ä¼˜åŒ–(å¹¶è¡Œã€ç¼“å­˜)
3. ğŸ”Œ æ’ä»¶åŒ–(å·¥å…·ã€é…ç½®)

**ä¸éœ€è¦å®Œå…¨ç…§æ¬Moltbot**ï¼Œé€‰æ‹©æ€§å€Ÿé‰´å³å¯ï¼

---

**æ–‡æ¡£ç»“æŸ**

å¸Œæœ›è¿™ä»½æ·±åº¦è®¨è®ºå¯¹æ‚¨æœ‰å¸®åŠ©ï¼
